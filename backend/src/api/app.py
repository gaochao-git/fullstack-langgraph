# mypy: disable - error - code = "no-untyped-def,misc"
import pathlib
import uuid
import logging
from datetime import datetime
from typing import Dict, Any, List, Optional
from fastapi import FastAPI, Response, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
import asyncio
import json
import os
# Import graphs
from src.agents.diagnostic_agent.graph import graph as diagnostic_graph
from src.agents.research_agent.graph import graph as research_graph
from src.agents.diagnostic_agent.configuration import Configuration as DiagnosticConfiguration
from src.agents.research_agent.configuration import Configuration as ResearchConfiguration

# Define the FastAPI app
app = FastAPI(title="LangGraph Server", version="1.0.0")

# åº”ç”¨å¯åŠ¨æ—¶æµ‹è¯•PostgreSQLè¿æ¥
@app.on_event("startup")
async def startup_event():
    await test_postgres_connection()

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


# In-memory storage for threads and runs (TODO: replace with persistent storage)
threads_store: Dict[str, Dict[str, Any]] = {}
runs_store: Dict[str, Dict[str, Any]] = {}
# Store message history for each thread
thread_messages: Dict[str, List[Dict[str, Any]]] = {}
# Store interrupt information for each thread
thread_interrupts: Dict[str, List[Dict[str, Any]]] = {}

# å…¨å±€è¿æ¥å­—ç¬¦ä¸²é…ç½®
POSTGRES_CONNECTION_STRING = "postgresql://postgres:fffjjj@82.156.146.51:5432/langgraph_memory"

async def test_postgres_connection():
    """å¯åŠ¨æ—¶æµ‹è¯•PostgreSQLè¿æ¥"""
    checkpointer_type = os.getenv("CHECKPOINTER_TYPE", "memory")
    if checkpointer_type == "postgres":
        try:
            from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
            async with AsyncPostgresSaver.from_conn_string(POSTGRES_CONNECTION_STRING) as checkpointer:
                await checkpointer.setup()
                logger.info("âœ… PostgreSQLè¿æ¥æµ‹è¯•æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ PostgreSQLè¿æ¥æµ‹è¯•å¤±è´¥: {e}")
            raise e

# çº¿ç¨‹æ¢å¤å·¥å…·å‡½æ•°
async def recover_thread_from_postgres(thread_id: str) -> bool:
    """ä»PostgreSQL checkpointerä¸­æ¢å¤çº¿ç¨‹ä¿¡æ¯"""
    try:
        checkpointer_type = os.getenv("CHECKPOINTER_TYPE", "memory")
        if checkpointer_type != "postgres":
            return False
            
        from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
        
        # æ¯æ¬¡åˆ›å»ºæ–°çš„checkpointerè¿æ¥æ¥æ¢å¤çº¿ç¨‹
        async with AsyncPostgresSaver.from_conn_string(POSTGRES_CONNECTION_STRING) as checkpointer:
            await checkpointer.setup()
            
            config = {"configurable": {"thread_id": thread_id}}
            # è·å–æœ€æ–°çš„checkpointæ¥éªŒè¯threadå­˜åœ¨
            history = [c async for c in checkpointer.alist(config, limit=1)]
            
            if history:
                logger.info(f"âœ… ä»PostgreSQLæ¢å¤çº¿ç¨‹: {thread_id}")
                checkpoint_tuple = history[0]
                
                # é‡å»ºthreads_storeæ¡ç›® - ä½¿ç”¨æ­£ç¡®çš„å±æ€§è®¿é—®
                threads_store[thread_id] = {
                    "thread_id": thread_id,
                    "created_at": checkpoint_tuple.metadata.get("created_at", datetime.now().isoformat()) if checkpoint_tuple.metadata else datetime.now().isoformat(),
                    "metadata": {},
                    "state": {},
                    "recovered_from_postgres": True
                }
                
                # åˆå§‹åŒ–ç›¸å…³å­˜å‚¨
                if thread_id not in thread_messages:
                    thread_messages[thread_id] = []
                if thread_id not in thread_interrupts:
                    thread_interrupts[thread_id] = []
                
                # ä»checkpointæ¢å¤æ¶ˆæ¯ - ä½¿ç”¨å®˜æ–¹ç»“æ„
                try:
                    if checkpoint_tuple.checkpoint and "channel_values" in checkpoint_tuple.checkpoint:
                        channel_values = checkpoint_tuple.checkpoint["channel_values"]
                        if "messages" in channel_values:
                            thread_messages[thread_id] = channel_values["messages"]
                            logger.info(f"æ¢å¤äº† {len(thread_messages[thread_id])} æ¡æ¶ˆæ¯")
                        
                        # ä¹Ÿå°è¯•æ¢å¤å…¶ä»–çŠ¶æ€
                        if "diagnosis_progress" in channel_values:
                            threads_store[thread_id]["state"]["diagnosis_progress"] = channel_values["diagnosis_progress"]
                        logger.info(f"ä»checkpointæ¢å¤çš„é€šé“: {list(channel_values.keys())}")
                    else:
                        logger.info(f"Checkpointç»“æ„: {list(checkpoint_tuple.checkpoint.keys()) if checkpoint_tuple.checkpoint else 'None'}")
                except Exception as e:
                    logger.warning(f"æ¢å¤çŠ¶æ€æ—¶å‡ºé”™ï¼Œä½†çº¿ç¨‹æ¢å¤æˆåŠŸ: {e}")
                
                return True
            else:
                logger.info(f"âŒ PostgreSQLä¸­æœªæ‰¾åˆ°çº¿ç¨‹: {thread_id}")
                return False
                
    except Exception as e:
        logger.error(f"æ¢å¤çº¿ç¨‹å¤±è´¥: {e}")
        return False

# Available assistants based on langgraph.json
ASSISTANTS = {
    "research_agent": {
        "assistant_id": "research_agent",
        "graph": research_graph,
        "config_class": ResearchConfiguration,
        "description": "Research agent for information gathering and analysis"
    },
    "diagnostic_agent": {
        "assistant_id": "diagnostic_agent", 
        "graph": diagnostic_graph,
        "config_class": DiagnosticConfiguration,
        "description": "Diagnostic agent for system troubleshooting"
    }
}

# Pydantic models
class ThreadCreate(BaseModel):
    metadata: Optional[Dict[str, Any]] = None

class ThreadResponse(BaseModel):
    thread_id: str
    created_at: str
    metadata: Dict[str, Any]

class RunCreate(BaseModel):
    assistant_id: str
    input: Optional[Dict[str, Any]] = None  # æ”¹ä¸ºå¯é€‰ï¼Œresumeæ—¶ä¸éœ€è¦input
    config: Optional[Dict[str, Any]] = None
    metadata: Optional[Dict[str, Any]] = None
    stream_mode: Optional[List[str]] = ["values"]  # ä¿®æ”¹ä¸ºæ•°ç»„ç±»å‹
    interrupt_before: Optional[List[str]] = None
    interrupt_after: Optional[List[str]] = None
    on_disconnect: Optional[str] = None  # æ·»åŠ å‰ç«¯å‘é€çš„å­—æ®µ
    command: Optional[Dict[str, Any]] = None  # æ·»åŠ commandå­—æ®µç”¨äºresume
    checkpoint: Optional[Dict[str, Any]] = None  # æ·»åŠ checkpointå­—æ®µ

class RunResponse(BaseModel):
    run_id: str
    thread_id: str
    assistant_id: str
    created_at: str
    status: str
    metadata: Dict[str, Any]

class AssistantResponse(BaseModel):
    assistant_id: str
    description: str

# Thread Management Endpoints
@app.post("/threads", response_model=ThreadResponse)
async def create_thread(thread_create: ThreadCreate):
    """Create a new thread"""
    thread_id = str(uuid.uuid4())
    thread_data = {
        "thread_id": thread_id,
        "created_at": datetime.now().isoformat(),
        "metadata": thread_create.metadata or {},
        "state": {}
    }
    threads_store[thread_id] = thread_data
    thread_messages[thread_id] = []  # Initialize empty message history
    thread_interrupts[thread_id] = []  # Initialize empty interrupt history
    logger.info(f"Created thread: {thread_id}")
    return ThreadResponse(**thread_data)

@app.get("/threads/{thread_id}", response_model=ThreadResponse)
async def get_thread(thread_id: str):
    """Get thread details"""
    if thread_id not in threads_store:
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            raise HTTPException(status_code=404, detail="Thread not found")
    return ThreadResponse(**threads_store[thread_id])

@app.get("/threads/{thread_id}/state")
async def get_thread_state(thread_id: str):
    """Get thread state"""
    if thread_id not in threads_store:
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            raise HTTPException(status_code=404, detail="Thread not found")
    return threads_store[thread_id].get("state", {})

@app.post("/threads/{thread_id}/state")
async def update_thread_state(thread_id: str, state: Dict[str, Any]):
    """Update thread state"""
    if thread_id not in threads_store:
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            raise HTTPException(status_code=404, detail="Thread not found")
    threads_store[thread_id]["state"] = state
    return {"success": True}

@app.get("/threads/{thread_id}/history")
async def get_thread_history(thread_id: str, limit: int = 10, before: Optional[str] = None):
    """Get all past states for a thread"""
    logger.info(f"è¯·æ±‚history - thread_id: {thread_id}")
    logger.info(f"å½“å‰threads_storeä¸­çš„thread_ids: {list(threads_store.keys())}")
    
    if thread_id not in threads_store:
        logger.warning(f"Thread {thread_id} æœªæ‰¾åˆ°åœ¨threads_storeä¸­ï¼Œå°è¯•ä»PostgreSQLæ¢å¤")
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            logger.error(f"Thread {thread_id} æ— æ³•ä»PostgreSQLæ¢å¤")
            raise HTTPException(status_code=404, detail="Thread not found")
        logger.info(f"âœ… æˆåŠŸä»PostgreSQLæ¢å¤çº¿ç¨‹: {thread_id}")
    
    thread_data = threads_store[thread_id]
    messages = thread_messages.get(thread_id, [])
    interrupts = thread_interrupts.get(thread_id, [])
    
    # Return history with actual messages and interrupt information
    history = [
        {
            "checkpoint": {
                "thread_id": thread_id,
                "checkpoint_ns": "",
                "checkpoint_id": str(uuid.uuid4()),
                "checkpoint_map": {}
            },
            "metadata": {
                "step": 0,
                "writes": {},
                "parents": {}
            },
            "values": {
                "messages": messages,
                **thread_data.get("state", {})
            },
            "next": [],
            "tasks": [
                {
                    "id": str(uuid.uuid4()),
                    "name": "current_task",
                    "interrupts": interrupts,
                    "error": None
                }
            ] if interrupts else [],
            "config": {
                "configurable": {
                    "thread_id": thread_id,
                    "checkpoint_ns": ""
                }
            },
            "created_at": thread_data.get("created_at"),
            "parent_config": None
        }
    ]
    
    return history[:limit]

@app.post("/threads/{thread_id}/history")
async def get_thread_history_post(thread_id: str, request_body: Optional[Dict[str, Any]] = None):
    """Get all past states for a thread (POST version)"""
    logger.info(f"è¯·æ±‚history(POST) - thread_id: {thread_id}")
    logger.info(f"å½“å‰threads_storeä¸­çš„thread_ids: {list(threads_store.keys())}")
    
    if thread_id not in threads_store:
        logger.warning(f"Thread {thread_id} æœªæ‰¾åˆ°åœ¨threads_storeä¸­ï¼Œå°è¯•ä»PostgreSQLæ¢å¤")
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            logger.error(f"Thread {thread_id} æ— æ³•ä»PostgreSQLæ¢å¤")
            raise HTTPException(status_code=404, detail="Thread not found")
        logger.info(f"âœ… æˆåŠŸä»PostgreSQLæ¢å¤çº¿ç¨‹: {thread_id}")
    
    # Extract parameters from request body if provided
    limit = 10
    before = None
    if request_body:
        limit = request_body.get("limit", 10)
        before = request_body.get("before", None)
    
    thread_data = threads_store[thread_id]
    messages = thread_messages.get(thread_id, [])
    interrupts = thread_interrupts.get(thread_id, [])
    
    # Return history with actual messages and interrupt information
    history = [
        {
            "checkpoint": {
                "thread_id": thread_id,
                "checkpoint_ns": "",
                "checkpoint_id": str(uuid.uuid4()),
                "checkpoint_map": {}
            },
            "metadata": {
                "step": 0,
                "writes": {},
                "parents": {}
            },
            "values": {
                "messages": messages,
                **thread_data.get("state", {})
            },
            "next": [],
            "tasks": [
                {
                    "id": str(uuid.uuid4()),
                    "name": "current_task",
                    "interrupts": interrupts,
                    "error": None
                }
            ] if interrupts else [],
            "config": {
                "configurable": {
                    "thread_id": thread_id,
                    "checkpoint_ns": ""
                }
            },
            "created_at": thread_data.get("created_at"),
            "parent_config": None
        }
    ]
    
    return history[:limit]

# Run Management Endpoints
@app.post("/threads/{thread_id}/runs", response_model=RunResponse)
async def create_run(thread_id: str, run_create: RunCreate):
    """Create and start a new run"""
    if thread_id not in threads_store:
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            raise HTTPException(status_code=404, detail="Thread not found")
    
    if run_create.assistant_id not in ASSISTANTS:
        raise HTTPException(status_code=400, detail="Invalid assistant_id")
    
    run_id = str(uuid.uuid4())
    run_data = {
        "run_id": run_id,
        "thread_id": thread_id,
        "assistant_id": run_create.assistant_id,
        "created_at": datetime.now().isoformat(),
        "status": "running",
        "metadata": run_create.metadata or {},
        "config": run_create.config or {},
        "input": run_create.input
    }
    runs_store[run_id] = run_data
    logger.info(f"Created run: {run_id} for thread: {thread_id}")
    
    # Start async run
    asyncio.create_task(_execute_run(run_id))
    
    return RunResponse(**run_data)

@app.get("/threads/{thread_id}/runs/{run_id}")
async def get_run(thread_id: str, run_id: str):
    """Get run details"""
    if run_id not in runs_store:
        raise HTTPException(status_code=404, detail="Run not found")
    
    run_data = runs_store[run_id]
    if run_data["thread_id"] != thread_id:
        raise HTTPException(status_code=404, detail="Run not found in thread")
    
    return run_data

# å·¥å…·å‡½æ•° - æå–åˆ°æ¨¡å—çº§åˆ«
def should_use_postgres_mode(assistant_id: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥ä½¿ç”¨PostgreSQLæ¨¡å¼"""
    checkpointer_type = os.getenv("CHECKPOINTER_TYPE", "memory")
    return assistant_id == "diagnostic_agent" and checkpointer_type == "postgres"

def prepare_graph_config(request_body, thread_id):
    """å‡†å¤‡å›¾æ‰§è¡Œé…ç½®"""
    config = {
        "configurable": {
            "thread_id": thread_id,
            **(request_body.config or {}).get("configurable", {})
        }
    }
    
    # Handle resume command for interrupted execution
    if request_body.command and "resume" in request_body.command:
        from langgraph.types import Command
        graph_input = Command(resume=request_body.command["resume"])
        logger.info(f"Resuming execution with command: {request_body.command}")
        # Clear interrupt information when resuming
        if thread_id in thread_interrupts:
            thread_interrupts[thread_id] = []
    elif request_body.input is not None:
        graph_input = request_body.input
    else:
        raise HTTPException(status_code=400, detail="Either 'input' or 'command' must be provided")
    
    # Use checkpoint from request if provided  
    checkpoint = request_body.checkpoint
    if checkpoint and "thread_id" in checkpoint:
        del checkpoint["thread_id"]
    
    # Combine stream modes
    stream_modes = list(set([
        "values", "messages", "updates", "custom", "checkpoints", "tasks"
    ] + (request_body.stream_mode or [])))
    
    return config, graph_input, stream_modes, checkpoint

def serialize_value(val):
    """é€šç”¨åºåˆ—åŒ–å‡½æ•°"""
    # Handle tuples (like from LangGraph messages)
    if isinstance(val, tuple):
        return [serialize_value(item) for item in val]
    # Handle LangGraph Interrupt objects
    elif hasattr(val, 'value') and hasattr(val, 'resumable') and hasattr(val, 'ns'):
        return {
            "value": serialize_value(val.value),
            "resumable": val.resumable,
            "ns": val.ns,
            "when": getattr(val, 'when', 'during')
        }
    elif hasattr(val, 'dict'):
        return val.dict()
    elif hasattr(val, 'to_dict'):
        return val.to_dict()
    elif hasattr(val, '__dict__'):
        result = {}
        for k, v in val.__dict__.items():
            if not k.startswith('_'):
                result[k] = serialize_value(v)
        return result
    elif isinstance(val, list):
        return [serialize_value(item) for item in val]
    elif isinstance(val, dict):
        return {k: serialize_value(v) for k, v in val.items()}
    else:
        try:
            json.dumps(val)
            return val
        except (TypeError, ValueError):
            return str(val)

async def process_stream_chunk(chunk, event_id, thread_id):
    """å¤„ç†å•ä¸ªæµå¼æ•°æ®å—"""
    # Handle tuple format from LangGraph streaming
    if isinstance(chunk, tuple) and len(chunk) == 2:
        event_type, data = chunk
        serialized_data = serialize_value(data)
        
        # Save messages to thread history from LangGraph state
        if event_type == "values" and isinstance(data, dict) and "messages" in data:
            if thread_id not in thread_messages:
                thread_messages[thread_id] = []
            thread_messages[thread_id] = [serialize_value(msg) for msg in data["messages"]]
        
        # Check for interrupts
        has_interrupt = False
        if event_type == "updates" and isinstance(data, dict) and "__interrupt__" in data:
            logger.info(f"Interrupt detected: {data}")
            if thread_id not in thread_interrupts:
                thread_interrupts[thread_id] = []
            thread_interrupts[thread_id].append(data["__interrupt__"][0])
            has_interrupt = True
        
        return f"id: {event_id}\nevent: {event_type}\ndata: {json.dumps(serialized_data, ensure_ascii=False)}\n\n", has_interrupt
    else:
        # Handle dict format (fallback)
        serializable_chunk = {}
        for key, value in chunk.items():
            serializable_chunk[key] = serialize_value(value)
        
        event_type = list(serializable_chunk.keys())[0] if serializable_chunk else "data"
        return f"id: {event_id}\nevent: {event_type}\ndata: {json.dumps(serializable_chunk[event_type], ensure_ascii=False)}\n\n", False

async def stream_with_graph_postgres(graph, request_body, thread_id):
    """PostgreSQLæ¨¡å¼ä¸“ç”¨çš„å›¾æµåª’ä½“å¤„ç†å‡½æ•°"""
    config, graph_input, stream_modes, checkpoint = prepare_graph_config(request_body, thread_id)
    logger.info(f"Starting stream with modes: {stream_modes}, checkpoint: {checkpoint}")
    
    event_id = 0
    has_interrupt = False
    
    async for chunk in graph.astream(graph_input, config=config, stream_mode=stream_modes):
        try:
            event_id += 1
            sse_data, chunk_has_interrupt = await process_stream_chunk(chunk, event_id, thread_id)
            yield sse_data
            if chunk_has_interrupt:
                has_interrupt = True
        except Exception as e:
            logger.error(f"Serialization error: {e}, chunk type: {type(chunk)}, chunk: {chunk}")
            event_id += 1
            yield f"id: {event_id}\nevent: error\ndata: {json.dumps({'error': str(e), 'chunk_type': str(type(chunk)), 'chunk': str(chunk)}, ensure_ascii=False)}\n\n"
    
    # End event - only send if no interrupt occurred
    if not has_interrupt:
        event_id += 1
        yield f"id: {event_id}\nevent: end\ndata: {json.dumps({'status': 'completed'}, ensure_ascii=False)}\n\n"
    else:
        logger.info("Skipping end event due to interrupt - waiting for user approval")

async def stream_with_graph(graph, request_body, thread_id):
    """é€šç”¨çš„å›¾æµåª’ä½“å¤„ç†å‡½æ•°"""
    config, graph_input, stream_modes, checkpoint = prepare_graph_config(request_body, thread_id)
    logger.info(f"Starting stream with modes: {stream_modes}, checkpoint: {checkpoint}")
    
    event_id = 0
    has_interrupt = False
    
    async for chunk in graph.astream(graph_input, config=config, stream_mode=stream_modes):
        try:
            event_id += 1
            sse_data, chunk_has_interrupt = await process_stream_chunk(chunk, event_id, thread_id)
            yield sse_data
            if chunk_has_interrupt:
                has_interrupt = True
        except Exception as e:
            logger.error(f"Serialization error: {e}, chunk type: {type(chunk)}, chunk: {chunk}")
            event_id += 1
            yield f"id: {event_id}\nevent: error\ndata: {json.dumps({'error': str(e), 'chunk_type': str(type(chunk)), 'chunk': str(chunk)}, ensure_ascii=False)}\n\n"
    
    # End event - only send if no interrupt occurred
    if not has_interrupt:
        event_id += 1
        yield f"id: {event_id}\nevent: end\ndata: {json.dumps({'status': 'completed'}, ensure_ascii=False)}\n\n"
    else:
        logger.info("Skipping end event due to interrupt - waiting for user approval")

async def handle_postgres_streaming(request_body, thread_id):
    """å¤„ç†PostgreSQLæ¨¡å¼çš„æµå¼å“åº”"""
    from src.agents.diagnostic_agent.graph import builder
    from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver
    
    logger.info(f"ğŸ” PostgreSQLæ¨¡å¼ - æŒ‰ç…§å®˜æ–¹æ¨¡å¼ä½¿ç”¨async with")
    if thread_id in threads_store:
        threads_store[thread_id]["streaming_status"] = "starting"
    
    # æŒ‰ç…§å®˜æ–¹æ¨¡å¼ï¼šåœ¨async withå†…å®Œæˆæ•´ä¸ªè¯·æ±‚å‘¨æœŸ
    async with AsyncPostgresSaver.from_conn_string(POSTGRES_CONNECTION_STRING) as checkpointer:
        await checkpointer.setup()
        graph = builder.compile(checkpointer=checkpointer, name="diagnostic-agent")
        
        # åœ¨åŒä¸€ä¸ªasync withå†…æ‰§è¡Œå®Œæ•´çš„æµå¼å¤„ç†
        async for item in stream_with_graph_postgres(graph, request_body, thread_id):
            yield item

async def handle_memory_streaming(request_body, thread_id):
    """å¤„ç†å†…å­˜æ¨¡å¼çš„æµå¼å“åº”"""
    assistant = ASSISTANTS[request_body.assistant_id]
    graph = assistant["graph"]
    
    # ä½¿ç”¨ç°æœ‰å›¾è¿›è¡Œæµå¼å¤„ç†
    async for item in stream_with_graph(graph, request_body, thread_id):
        yield item

# LangGraphæ ‡å‡†çš„æµåª’ä½“ç«¯ç‚¹
@app.post("/threads/{thread_id}/runs/stream")
async def stream_run_standard(thread_id: str, request_body: RunCreate):
    """Standard LangGraph streaming endpoint"""
    if thread_id not in threads_store:
        # å°è¯•ä»PostgreSQLæ¢å¤çº¿ç¨‹
        recovered = await recover_thread_from_postgres(thread_id)
        if not recovered:
            raise HTTPException(status_code=404, detail="Thread not found")
    if request_body.assistant_id not in ASSISTANTS: 
        raise HTTPException(status_code=400, detail="Invalid assistant_id")

    async def generate():
        try:
            # æ ¹æ®åŠ©æ‰‹ç±»å‹å’Œcheckpointerç±»å‹é€‰æ‹©å¤„ç†ç­–ç•¥
            if should_use_postgres_mode(request_body.assistant_id):
                async for item in handle_postgres_streaming(request_body, thread_id):
                    yield item
            else:
                async for item in handle_memory_streaming(request_body, thread_id):
                    yield item
                
        except Exception as e:
            logger.error(f"Error in streaming: {e}")
            yield f"event: error\n"
            yield f"data: {json.dumps({'type': 'error', 'error': str(e)}, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Content-Type": "text/event-stream"
        }
    )


@app.post("/threads/{thread_id}/runs/{run_id}/interrupt")
async def interrupt_run(thread_id: str, run_id: str):
    """Interrupt a running run"""
    if run_id not in runs_store:
        raise HTTPException(status_code=404, detail="Run not found")
    
    runs_store[run_id]["status"] = "interrupted"
    return {"success": True, "run_id": run_id}

@app.post("/threads/{thread_id}/runs/{run_id}/resume")
async def resume_run(thread_id: str, run_id: str, command: Optional[Dict[str, Any]] = None):
    """Resume an interrupted run"""
    if run_id not in runs_store:
        raise HTTPException(status_code=404, detail="Run not found")
    
    runs_store[run_id]["status"] = "running"
    # TODO: Implement actual resume logic with command
    return {"success": True, "run_id": run_id}

# Assistant Management Endpoints
@app.get("/assistants", response_model=List[AssistantResponse])
async def list_assistants():
    """List available assistants"""
    return [
        AssistantResponse(
            assistant_id=assistant_id,
            description=assistant["description"]
        )
        for assistant_id, assistant in ASSISTANTS.items()
    ]

@app.get("/assistants/{assistant_id}", response_model=AssistantResponse)
async def get_assistant(assistant_id: str):
    """Get assistant details"""
    if assistant_id not in ASSISTANTS:
        raise HTTPException(status_code=404, detail="Assistant not found")
    
    assistant = ASSISTANTS[assistant_id]
    return AssistantResponse(
        assistant_id=assistant_id,
        description=assistant["description"]
    )

# Helper function to execute runs
async def _execute_run(run_id: str):
    """Execute a run asynchronously"""
    try:
        run_data = runs_store[run_id]
        assistant = ASSISTANTS[run_data["assistant_id"]]
        graph = assistant["graph"]
        
        # Build config
        config = {
            "configurable": run_data.get("config", {}),
            "thread_id": run_data["thread_id"]
        }
        
        # Execute the graph
        result = await graph.ainvoke(run_data["input"], config=config)
        
        # Update thread state with result
        threads_store[run_data["thread_id"]]["state"].update(result)
        runs_store[run_id]["status"] = "completed"
        runs_store[run_id]["result"] = result
        
    except Exception as e:
        logger.error(f"Error executing run {run_id}: {e}")
        runs_store[run_id]["status"] = "failed"
        runs_store[run_id]["error"] = str(e)


def create_frontend_router(build_dir="../frontend/dist"):
    """Creates a router to serve the React frontend.

    Args:
        build_dir: Path to the React build directory relative to this file.

    Returns:
        A Starlette application serving the frontend.
    """
    build_path = pathlib.Path(__file__).parent.parent.parent / build_dir

    if not build_path.is_dir() or not (build_path / "index.html").is_file():
        print(
            f"WARN: Frontend build directory not found or incomplete at {build_path}. Serving frontend will likely fail."
        )
        # Return a dummy router if build isn't ready
        from starlette.routing import Route

        async def dummy_frontend(request):
            return Response(
                "Frontend not built. Run 'npm run build' in the frontend directory.",
                media_type="text/plain",
                status_code=503,
            )

        return Route("/{path:path}", endpoint=dummy_frontend)

    return StaticFiles(directory=build_path, html=True)


# Mount the frontend under /app to not conflict with the LangGraph API routes
app.mount(
    "/app",
    create_frontend_router(),
    name="frontend",
) 