"""
æ•…éšœè¯Šæ–­ä»£ç† - ä½¿ç”¨LangGraphæ¶æ„ï¼ŒåŸºäºSOPçŸ¥è¯†åº“å’Œæ™ºèƒ½å·¥å…·é€‰æ‹©
é‡æ„ç‰ˆæœ¬ï¼šå‚è€ƒè°ƒç ”agentçš„ç»“æ„ï¼Œä¼˜åŒ–çŠ¶æ€ç®¡ç†å’ŒèŠ‚ç‚¹èŒè´£
"""

import os
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Send, interrupt

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langchain_deepseek import ChatDeepSeek

from agents.diagnostic_agent.state import (
    DiagnosticState,
    QuestionAnalysis,
    DiagnosisProgress,
    SOPDetail,
    SOPStep,
)
from agents.diagnostic_agent.configuration import Configuration
from agents.diagnostic_agent.prompts import (
    get_current_date,
    question_analysis_instructions,
    tool_planning_instructions,
    reflection_instructions,
    final_diagnosis_instructions,
)
from agents.diagnostic_agent.tools_and_schemas import QuestionInfoExtraction

# å¯¼å…¥å·¥å…·
from tools import ssh_tool, sop_tool
from dotenv import load_dotenv

load_dotenv()

if os.getenv("DEEPSEEK_API_KEY") is None:
    raise ValueError("DEEPSEEK_API_KEY is not set")

logger = logging.getLogger(__name__)


# èŠ‚ç‚¹å‡½æ•° - å‚è€ƒè°ƒç ”agentçš„æ¸…æ™°ç»“æ„
def analyze_question(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """é—®é¢˜åˆ†æèŠ‚ç‚¹ - ç±»ä¼¼è°ƒç ”agentçš„generate_query"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=1.0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    messages = state.get("messages", [])
    user_question = messages[-1].content if messages else ""
    
    # æ ¼å¼åŒ–æç¤ºè¯
    current_date = get_current_date()
    formatted_prompt = question_analysis_instructions.format(
        current_date=current_date,
        user_question=user_question
    )
    
    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè§£æç”¨æˆ·è¾“å…¥
    result = llm.with_structured_output(QuestionInfoExtraction).invoke(formatted_prompt)
    
    # æ£€æŸ¥å››è¦ç´ æ˜¯å¦éƒ½æœ‰æœ‰æ•ˆå€¼
    info_sufficient = (
        result.fault_ip and result.fault_ip.strip() and result.fault_ip != "å¾…æå–" and
        result.fault_time and result.fault_time.strip() and result.fault_time != "å¾…æå–" and
        result.fault_info and result.fault_info.strip() and result.fault_info != "å¾…æå–" and
        result.sop_id and result.sop_id.strip() and result.sop_id != "å¾…æå–"
    )
    
    # ç”Ÿæˆç¼ºå¤±å­—æ®µåˆ—è¡¨
    missing_fields = []
    if not result.fault_ip or result.fault_ip.strip() == "" or result.fault_ip == "å¾…æå–":
        missing_fields.append("æ•…éšœIP")
    if not result.fault_time or result.fault_time.strip() == "" or result.fault_time == "å¾…æå–":
        missing_fields.append("æ•…éšœæ—¶é—´")
    if not result.fault_info or result.fault_info.strip() == "" or result.fault_info == "å¾…æå–":
        missing_fields.append("æ•…éšœç°è±¡")
    if not result.sop_id or result.sop_id.strip() == "" or result.sop_id == "å¾…æå–":
        missing_fields.append("æ’æŸ¥SOPç¼–å·")
    
    # åˆ›å»ºQuestionAnalysiså¯¹è±¡
    question_analysis = QuestionAnalysis(
        fault_ip=result.fault_ip,
        fault_time=result.fault_time,
        fault_info=result.fault_info,
        sop_id=result.sop_id,
        missing_fields=missing_fields,
        info_sufficient=info_sufficient
    )
    
    return {
        "user_question": user_question,
        "question_analysis": question_analysis
    }


def plan_diagnosis_tools(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """å·¥å…·è§„åˆ’èŠ‚ç‚¹ - ä¸¥æ ¼æŒ‰ç…§SOPæ‰§è¡Œ"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œç¡®ä¿ä¸¥æ ¼æ‰§è¡Œ
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    ssh_tools = [
        ssh_tool.get_system_info,
        ssh_tool.analyze_processes,
        ssh_tool.check_service_status,
        ssh_tool.analyze_system_logs,
        ssh_tool.execute_system_command
    ]
    sop_tools = [
        sop_tool.get_sop_content,
        sop_tool.get_sop_detail,
        sop_tool.list_sops,
        sop_tool.search_sops
    ]
    all_tools = ssh_tools + sop_tools
    llm_with_tools = llm.bind_tools(all_tools)
    
    # æ„å»ºå·¥å…·è§„åˆ’æç¤º
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    sop_detail = state.get("sop_detail", SOPDetail())
    sop_state = "loaded" if state.get("sop_loaded", False) else "none"
    
    formatted_prompt = tool_planning_instructions.format(
        fault_ip=question_analysis.fault_ip or "",
        fault_time=question_analysis.fault_time or "",
        fault_info=question_analysis.fault_info or "",
        sop_id=question_analysis.sop_id or "",
        sop_state=sop_state,
        sop_content=sop_detail.description if sop_detail else ""
    )

    # æ„å»ºæ¶ˆæ¯
    messages = state.get("messages", [])
    system_message = SystemMessage(content=formatted_prompt)
    messages_with_system = [system_message] + messages
    
    # è°ƒç”¨LLMç”Ÿæˆå·¥å…·è°ƒç”¨
    response = llm_with_tools.invoke(messages_with_system)
    
    # è¿”å›æ–°çš„æ¶ˆæ¯ï¼ŒLangGraphä¼šå°†å…¶æ·»åŠ åˆ°çŠ¶æ€ä¸­
    return {"messages": [response]}


def approval_node(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """SOPæ‰§è¡Œç¡®è®¤èŠ‚ç‚¹ - ç¡®è®¤æ¯ä¸ªSOPæ­¥éª¤çš„æ‰§è¡Œ"""
    # è·å–æœ€æ–°çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
    messages = state.get("messages", [])
    if not messages:
        return {}
    
    last_message = messages[-1]
    
    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆSOPè¦æ±‚
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        tool_calls = last_message.tool_calls
        question_analysis = state.get("question_analysis", QuestionAnalysis())
        sop_detail = state.get("sop_detail", SOPDetail())
        diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
        
        # ä»SOPè¯¦æƒ…ä¸­è·å–å½“å‰æ­¥éª¤
        current_step_info = None
        if sop_detail.steps and 0 <= diagnosis_progress.current_step < len(sop_detail.steps):
            current_step_info = sop_detail.steps[diagnosis_progress.current_step]

        # æ£€æŸ¥å½“å‰æ­¥éª¤æ˜¯å¦éœ€è¦å®¡æ‰¹
        if current_step_info and current_step_info.requires_approval:
            tool_descriptions = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("name", "")
                tool_args = tool_call.get("args", {})
                tool_descriptions.append(f"å·¥å…·: {tool_name}, å‚æ•°: {tool_args}")
            
            # ä¸­æ–­å¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤
            interrupt_info = {
                "message": f"æŒ‰ç…§SOP '{question_analysis.sop_id}' è¦æ±‚ï¼Œå³å°†æ‰§è¡Œéœ€è¦å®¡æ‰¹çš„æ­¥éª¤:\n\n"
                           f"**æ­¥éª¤è¯¦æƒ…:** {current_step_info.action}\n"
                           f"**è®¡åˆ’æ“ä½œ:**\n" + "\n".join(tool_descriptions) +
                           f"\n\nç¡®è®¤æ‰§è¡Œï¼Ÿ",
                "tool_calls": tool_calls,
                "sop_id": question_analysis.sop_id,
                "current_sop_step": current_step_info.action,
                "suggestion_type": "sop_execution"
            }
            return interrupt(interrupt_info)
        
        # å¦‚æœä¸éœ€è¦å®¡æ‰¹ï¼Œåˆ™ä¸è¿”å›ä»»ä½•å†…å®¹ï¼Œç›´æ¥ç»§ç»­
    return {}


def reflect_diagnosis_progress(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """è¯Šæ–­åæ€èŠ‚ç‚¹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥æ›´æ–°è¯Šæ–­è¿›åº¦"""
    configurable = Configuration.from_runnable_config(config)
    
    # è·å–å½“å‰çŠ¶æ€
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    sop_detail = state.get("sop_detail", SOPDetail())
    messages = state.get("messages", [])
    
    # æ›´æ–°æ­¥éª¤è®¡æ•°
    current_step = diagnosis_progress.current_step + 1
    
    # ä»æœ€æ–°çš„ToolMessageä¸­æå–è¯Šæ–­ç»“æœ
    diagnosis_results = list(state.get("diagnosis_results", []))
    if messages and isinstance(messages[-1], ToolMessage):
        last_message = messages[-1]
        diagnosis_results.append(f"Tool: {last_message.name}, Result: {last_message.content}")
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆè¯Šæ–­
    is_complete = False
    termination_reason = "continue"
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•° (è®¾ç½®å®‰å…¨é»˜è®¤å€¼)
    max_steps = max(diagnosis_progress.max_steps, 5)  # è‡³å°‘5æ­¥
    if current_step >= max_steps:
        is_complete = True
        termination_reason = "max_steps_reached"
    # æ£€æŸ¥æ˜¯å¦å®Œæˆæ‰€æœ‰SOPæ­¥éª¤ (æ·»åŠ å®‰å…¨æ£€æŸ¥)
    elif sop_detail.steps and len(sop_detail.steps) > 0 and current_step >= len(sop_detail.steps):
        is_complete = True
        termination_reason = "sop_completed"
    # å®‰å…¨é€€å‡ºï¼šå¦‚æœæ²¡æœ‰SOPæ­¥éª¤ä¸”å·²æ‰§è¡Œäº†3æ­¥ï¼Œä¹Ÿè¦ç»“æŸ
    elif (not sop_detail.steps or len(sop_detail.steps) == 0) and current_step >= 3:
        is_complete = True
        termination_reason = "no_sop_fallback"
    
    # æ›´æ–°è¯Šæ–­è¿›åº¦
    updated_progress = DiagnosisProgress(
        current_step=current_step,
        max_steps=diagnosis_progress.max_steps,
        is_complete=is_complete,
        confidence_score=min(current_step / max(sop_detail.total_steps, 1), 1.0),
        termination_reason=termination_reason
    )
    
    return {
        "diagnosis_progress": updated_progress,
        "diagnosis_results": diagnosis_results
    }


def finalize_diagnosis_report(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """å®Œæˆè¯Šæ–­æŠ¥å‘ŠèŠ‚ç‚¹ - åŸºäºä¸¥æ ¼çš„SOPæ‰§è¡Œç»“æœ"""
    configurable = Configuration.from_runnable_config(config)
    
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    llm = ChatDeepSeek(
        model=configurable.answer_model,
        temperature=0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # è·å–çŠ¶æ€ä¿¡æ¯
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    sop_detail = state.get("sop_detail", SOPDetail())
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    diagnosis_results = state.get("diagnosis_results", [])
    
    # æ„å»ºSOPæ‰§è¡ŒæŠ¥å‘Š
    current_date = get_current_date()
    
    sop_execution_report = f"""
ã€æ•…éšœè¯Šæ–­æŠ¥å‘Šã€‘
è¯Šæ–­æ—¥æœŸï¼š{current_date}

åŸºæœ¬ä¿¡æ¯ï¼š
- æ•…éšœIPï¼š{question_analysis.fault_ip or 'æœªæä¾›'}
- æ•…éšœæ—¶é—´ï¼š{question_analysis.fault_time or 'æœªæä¾›'}
- æ•…éšœç°è±¡ï¼š{question_analysis.fault_info or 'æœªæä¾›'}
- ä½¿ç”¨SOPï¼š{question_analysis.sop_id or 'æœªæŒ‡å®š'}

æ‰§è¡Œè¿›åº¦ï¼š
- å½“å‰æ­¥éª¤ï¼š{diagnosis_progress.current_step}/{sop_detail.total_steps}
- å®ŒæˆçŠ¶æ€ï¼š{'å·²å®Œæˆ' if diagnosis_progress.is_complete else 'è¿›è¡Œä¸­'}
- ç½®ä¿¡åº¦ï¼š{diagnosis_progress.confidence_score:.2f}

è¯Šæ–­è¿‡ç¨‹ï¼š
{chr(10).join(diagnosis_results) if diagnosis_results else 'æœªè¿›è¡Œè¯Šæ–­'}

è¯·åŸºäºä»¥ä¸Šæ‰§è¡Œç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„è¯Šæ–­æŠ¥å‘Šã€‚
"""
    
    # è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
    response = llm.invoke(sop_execution_report)
    
    final_message = f"""
{response.content}

ğŸ“Š è¯Šæ–­æ‰§è¡Œæ‘˜è¦ï¼š
- ä½¿ç”¨SOPï¼š{question_analysis.sop_id}
- æ‰§è¡Œæ­¥éª¤ï¼š{diagnosis_progress.current_step}/{sop_detail.total_steps}
- å®ŒæˆçŠ¶æ€ï¼š{'âœ… å·²å®Œæˆ' if diagnosis_progress.is_complete else 'ğŸ”„ è¿›è¡Œä¸­'}
- ç½®ä¿¡åº¦ï¼š{diagnosis_progress.confidence_score:.1%}

âš ï¸ é‡è¦æé†’ï¼š
ä»¥ä¸Šè¯Šæ–­ç»“æœåŸºäºSOPæ‰§è¡Œã€‚åœ¨æ‰§è¡Œä»»ä½•æ“ä½œå‰ï¼Œè¯·ç¡®è®¤ç³»ç»ŸçŠ¶æ€å¹¶è¯„ä¼°é£é™©ã€‚
"""
    
    return {
        "messages": [AIMessage(content=final_message)],
        "final_diagnosis": response.content
    }


# è·¯ç”±å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬
def check_info_sufficient(state: DiagnosticState, config: RunnableConfig) -> str:
    """æ£€æŸ¥ä¿¡æ¯æ˜¯å¦å……è¶³"""
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    return "plan_tools" if question_analysis.info_sufficient else "finalize_answer"


def evaluate_diagnosis_progress(state: DiagnosticState, config: RunnableConfig) -> str:
    """è¯„ä¼°è¯Šæ–­è¿›åº¦ï¼Œæ ¹æ®æ‰§è¡Œæƒ…å†µå†³å®šä¸‹ä¸€æ­¥"""
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    
    # å®‰å…¨æ£€æŸ¥ï¼šå¼ºåˆ¶æœ€å¤§æ­¥éª¤é™åˆ¶
    if diagnosis_progress.current_step >= 10:  # ç¡¬ç¼–ç æœ€å¤§æ­¥éª¤æ•°
        logger.warning(f"å¼ºåˆ¶ç»ˆæ­¢ï¼šæ­¥éª¤æ•°è¾¾åˆ°å®‰å…¨ä¸Šé™ {diagnosis_progress.current_step}")
        return "finalize_answer"
    
    # å¦‚æœè¯Šæ–­å®Œæˆï¼Œç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    if diagnosis_progress.is_complete:
        logger.info(f"è¯Šæ–­å®Œæˆ: {diagnosis_progress.termination_reason}")
        return "finalize_answer"
    else:
        # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
        logger.info(f"ç»§ç»­æ‰§è¡Œï¼Œå½“å‰æ­¥éª¤: {diagnosis_progress.current_step}")
        return "plan_tools"


# åˆ›å»ºè¯Šæ–­Agentå›¾ - ç®€åŒ–ç‰ˆæœ¬
builder = StateGraph(DiagnosticState, config_schema=Configuration)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("analyze_question", analyze_question)
builder.add_node("plan_tools", plan_diagnosis_tools)
builder.add_node("approval", approval_node)

# åˆ›å»ºå·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
ssh_tools = [
    ssh_tool.get_system_info,
    ssh_tool.analyze_processes,
    ssh_tool.check_service_status,
    ssh_tool.analyze_system_logs,
    ssh_tool.execute_system_command
]
sop_tools = [
    sop_tool.get_sop_content,
    sop_tool.get_sop_detail,
    sop_tool.list_sops,
    sop_tool.search_sops
]
all_tools = ssh_tools + sop_tools
tool_node = ToolNode(all_tools)
builder.add_node("execute_tools", tool_node)

builder.add_node("reflection", reflect_diagnosis_progress)
builder.add_node("finalize_answer", finalize_diagnosis_report)

# æ·»åŠ è¾¹ - å‚è€ƒè°ƒç ”agentçš„æ¸…æ™°è¾¹è¿æ¥
builder.add_edge(START, "analyze_question")
builder.add_conditional_edges(
    "analyze_question", 
    check_info_sufficient, 
    ["plan_tools", "finalize_answer"]
)

# ä¿®å¤ï¼šä½¿ç”¨tools_conditionæ¥å†³å®šæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
builder.add_conditional_edges(
    "plan_tools",
    tools_condition,
    {
        "tools": "approval",
        "__end__": "finalize_answer"  # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥ç»“æŸ
    }
)

builder.add_edge("approval", "execute_tools")
builder.add_edge("execute_tools", "reflection")

builder.add_conditional_edges(
    "reflection", 
    evaluate_diagnosis_progress, 
    ["plan_tools", "finalize_answer"]
)
builder.add_edge("finalize_answer", END)

# ç¼–è¯‘å›¾
graph = builder.compile(name="diagnostic-agent")

# ä¿å­˜å›¾åƒ
graph_image = graph.get_graph().draw_mermaid_png()
with open("diagnostic_agent_graph.png", "wb") as f: 
    f.write(graph_image)
print("å›¾å·²ä¿å­˜åˆ°: diagnostic_agent_graph.png")