"""
æ•…éšœè¯Šæ–­ä»£ç† - ä½¿ç”¨LangGraphæ¶æ„ï¼ŒåŸºäºSOPçŸ¥è¯†åº“å’Œæ™ºèƒ½å·¥å…·é€‰æ‹©
é‡æ„ç‰ˆæœ¬ï¼šå‚è€ƒè°ƒç ”agentçš„ç»“æ„ï¼Œä¼˜åŒ–çŠ¶æ€ç®¡ç†å’ŒèŠ‚ç‚¹èŒè´£
"""

import os
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Send, interrupt

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langchain_deepseek import ChatDeepSeek

from agents.diagnostic_agent.state import (
    DiagnosticOverallState,
    QuestionAnalysisState,
    DiagnosisReflectionState,
    ToolPlanningState,
)
from agents.diagnostic_agent.configuration import Configuration
from agents.diagnostic_agent.prompts import (
    get_current_date,
    question_analysis_instructions,
    tool_planning_instructions,
    reflection_instructions,
    final_diagnosis_instructions,
)
from agents.diagnostic_agent.tools_and_schemas import QuestionInfoExtraction

# å¯¼å…¥å·¥å…·
from tools import ssh_tool, sop_tool
from dotenv import load_dotenv

load_dotenv()

if os.getenv("DEEPSEEK_API_KEY") is None:
    raise ValueError("DEEPSEEK_API_KEY is not set")

logger = logging.getLogger(__name__)


# èŠ‚ç‚¹å‡½æ•° - å‚è€ƒè°ƒç ”agentçš„æ¸…æ™°ç»“æ„
def analyze_question(state: DiagnosticOverallState, config: RunnableConfig) -> QuestionAnalysisState:
    """é—®é¢˜åˆ†æèŠ‚ç‚¹ - ç±»ä¼¼è°ƒç ”agentçš„generate_query"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=1.0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    messages = state.get("messages", [])
    user_question = messages[-1].content if messages else ""
    
    # æ ¼å¼åŒ–æç¤ºè¯
    current_date = get_current_date()
    formatted_prompt = question_analysis_instructions.format(
        current_date=current_date,
        user_question=user_question
    )
    
    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè§£æç”¨æˆ·è¾“å…¥
    result = llm.with_structured_output(QuestionInfoExtraction).invoke(formatted_prompt)
    
    # æ£€æŸ¥å››è¦ç´ æ˜¯å¦éƒ½æœ‰æœ‰æ•ˆå€¼
    info_sufficient = (
        result.fault_ip and result.fault_ip.strip() and result.fault_ip != "å¾…æå–" and
        result.fault_time and result.fault_time.strip() and result.fault_time != "å¾…æå–" and
        result.fault_info and result.fault_info.strip() and result.fault_info != "å¾…æå–" and
        result.sop_id and result.sop_id.strip() and result.sop_id != "å¾…æå–"
    )
    
    # ç”Ÿæˆç¼ºå¤±å­—æ®µåˆ—è¡¨
        missing_fields = []
        if not result.fault_ip or result.fault_ip.strip() == "" or result.fault_ip == "å¾…æå–":
            missing_fields.append("æ•…éšœIP")
        if not result.fault_time or result.fault_time.strip() == "" or result.fault_time == "å¾…æå–":
            missing_fields.append("æ•…éšœæ—¶é—´")
        if not result.fault_info or result.fault_info.strip() == "" or result.fault_info == "å¾…æå–":
            missing_fields.append("æ•…éšœç°è±¡")
        if not result.sop_id or result.sop_id.strip() == "" or result.sop_id == "å¾…æå–":
            missing_fields.append("æ’æŸ¥SOPç¼–å·")
        
    return {
        "fault_ip": result.fault_ip,
        "fault_time": result.fault_time,
        "fault_info": result.fault_info,
        "sop_id": result.sop_id,
        "info_sufficient": info_sufficient,
        "missing_fields": missing_fields,
    }


def plan_diagnosis_tools(state: DiagnosticOverallState, config: RunnableConfig) -> DiagnosticOverallState:
    """å·¥å…·è§„åˆ’èŠ‚ç‚¹ - ä¸¥æ ¼æŒ‰ç…§SOPæ‰§è¡Œ"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œç¡®ä¿ä¸¥æ ¼æ‰§è¡Œ
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    ssh_tools = [
        ssh_tool.get_system_info,
        ssh_tool.analyze_processes,
        ssh_tool.check_service_status,
        ssh_tool.analyze_system_logs,
        ssh_tool.execute_system_command
    ]
    sop_tools = [
        sop_tool.get_sop_content,
        sop_tool.get_sop_detail,
        sop_tool.list_sops,
        sop_tool.search_sops
    ]
    all_tools = ssh_tools + sop_tools
    llm_with_tools = llm.bind_tools(all_tools)
    
    # æ„å»ºå·¥å…·è§„åˆ’æç¤º
    sop_content = state.get("sop_detail", "")
    sop_state = state.get("sop_state", "none")
    
    formatted_prompt = tool_planning_instructions.format(
        fault_ip=state.get("fault_ip", ""),
        fault_time=state.get("fault_time", ""),
        fault_info=state.get("fault_info", ""),
        sop_id=state.get("sop_id", ""),
        sop_state=sop_state,
        sop_content=sop_content
    )

    # æ„å»ºæ¶ˆæ¯
    messages = state.get("messages", [])
    system_message = SystemMessage(content=formatted_prompt)
    messages_with_system = [system_message] + messages
    
    # è°ƒç”¨LLMç”Ÿæˆå·¥å…·è°ƒç”¨
    response = llm_with_tools.invoke(messages_with_system)
    
    # è¿”å›æ–°çš„æ¶ˆæ¯ï¼ŒLangGraphä¼šå°†å…¶æ·»åŠ åˆ°çŠ¶æ€ä¸­
    return {"messages": [response]}


def approval_node(state: DiagnosticOverallState, config: RunnableConfig) -> DiagnosticOverallState:
    """SOPæ‰§è¡Œç¡®è®¤èŠ‚ç‚¹ - ç¡®è®¤æ¯ä¸ªSOPæ­¥éª¤çš„æ‰§è¡Œ"""
    # è·å–æœ€æ–°çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
    messages = state.get("messages", [])
    if not messages:
        return {}
    
    last_message = messages[-1]
    
    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆSOPè¦æ±‚
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        tool_calls = last_message.tool_calls
        sop_id = state.get("sop_id", "")
        sop_detail = state.get("sop_detail", {})
        diagnosis_step_count = state.get("diagnosis_step_count", 0)
        
        # ä»SOPè¯¦æƒ…ä¸­è·å–å½“å‰æ­¥éª¤
        current_step_info = None
        if sop_detail and isinstance(sop_detail, dict):
            steps = sop_detail.get("steps", [])
            if 0 <= diagnosis_step_count < len(steps):
                current_step_info = steps[diagnosis_step_count]

        # æ£€æŸ¥å½“å‰æ­¥éª¤æ˜¯å¦éœ€è¦å®¡æ‰¹
        if current_step_info and current_step_info.get("requires_approval", False):
            tool_descriptions = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("name", "")
                tool_args = tool_call.get("args", {})
                tool_descriptions.append(f"å·¥å…·: {tool_name}, å‚æ•°: {tool_args}")
            
            # ä¸­æ–­å¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤
            interrupt_info = {
                "message": f"æŒ‰ç…§SOP '{sop_id}' è¦æ±‚ï¼Œå³å°†æ‰§è¡Œéœ€è¦å®¡æ‰¹çš„æ­¥éª¤:\n\n"
                           f"**æ­¥éª¤è¯¦æƒ…:** {current_step_info.get('action', 'N/A')}\n"
                           f"**è®¡åˆ’æ“ä½œ:**\n" + "\n".join(tool_descriptions) +
                           f"\n\nç¡®è®¤æ‰§è¡Œï¼Ÿ",
                "tool_calls": tool_calls,
                "sop_id": sop_id,
                "current_sop_step": current_step_info.get('action', ''),
                "suggestion_type": "sop_execution"
            }
            return interrupt(interrupt_info)
        
        # å¦‚æœä¸éœ€è¦å®¡æ‰¹ï¼Œåˆ™ä¸è¿”å›ä»»ä½•å†…å®¹ï¼Œç›´æ¥ç»§ç»­
    return {}


def execute_diagnosis_tools(state: DiagnosticOverallState, config: RunnableConfig) -> DiagnosticOverallState:
    """å·¥å…·æ‰§è¡ŒèŠ‚ç‚¹ - ä½¿ç”¨ToolNodeæ‰§è¡Œå·¥å…·"""
    # è¿™ä¸ªèŠ‚ç‚¹ä¼šè¢«ToolNodeæ›¿ä»£ï¼Œä½†æˆ‘ä»¬éœ€è¦åœ¨è¿™é‡Œå¤„ç†å·¥å…·æ‰§è¡Œåçš„çŠ¶æ€æ›´æ–°
    # å¢åŠ ä¸€ä¸ªç©ºè¿”å›ï¼Œå› ä¸ºæ‰€æœ‰èŠ‚ç‚¹éƒ½éœ€è¦è¿”å›ä¸€ä¸ªå­—å…¸
    return {}


def reflect_diagnosis_progress(state: DiagnosticOverallState, config: RunnableConfig) -> DiagnosisReflectionState:
    """è¯Šæ–­åæ€èŠ‚ç‚¹ - æŒ‰SOPé¡ºåºæ‰§è¡Œï¼Œæ‰¾åˆ°æ ¹å› å¯æå‰ç»“æŸ"""
    # 1. åŒæ­¥SOPçŠ¶æ€å¹¶æ›´æ–°æ­¥éª¤è®¡æ•°å™¨
    updated_state = sync_sop_state_from_messages(state)
    diagnosis_step_count = updated_state.get("diagnosis_step_count", 0)
    
    # ä¸ºä¸‹ä¸€æ­¥æ‰§è¡Œå¢åŠ æ­¥éª¤è®¡æ•°
    updated_state["diagnosis_step_count"] = diagnosis_step_count + 1

    # 2. å‡†å¤‡åæ€
    configurable = Configuration.from_runnable_config(config)
    
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    llm = ChatDeepSeek(
        model=configurable.reflection_model,
        temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œç¡®ä¿ä¸¥æ ¼æ£€æŸ¥
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # ä»æœ€æ–°çš„ToolMessageä¸­æå–è¯Šæ–­ç»“æœ
    diagnosis_results = updated_state.get("diagnosis_results", [])
    last_message = updated_state.get("messages", [])[-1]
    if isinstance(last_message, ToolMessage):
        diagnosis_results.append(f"Tool: {last_message.name}, Result: {last_message.content}")

    # æ ¼å¼åŒ–åæ€æç¤º
    formatted_prompt = reflection_instructions.format(
        diagnosis_step_count=diagnosis_step_count, # ä½¿ç”¨å½“å‰æ­¥éª¤æ•°è¿›è¡Œåæ€
        max_diagnosis_steps=updated_state.get("max_diagnosis_steps", 10),
        fault_info=updated_state.get("fault_info", ""),
        sop_state=updated_state.get("sop_state", "none"),
        diagnosis_results="\n".join(diagnosis_results)
    )
    
    # è°ƒç”¨LLMè¿›è¡ŒSOPæ‰§è¡Œæ£€æŸ¥å’Œæ ¹å› åˆ†æ
    try:
        from agents.diagnostic_agent.tools_and_schemas import DiagnosisReflectionOutput
        result = llm.with_structured_output(DiagnosisReflectionOutput).invoke(formatted_prompt)
    
    return {
            "is_complete": result.is_complete,
            "confidence_score": result.confidence_score,
            "sop_steps_completed": result.sop_steps_completed,
            "sop_steps_remaining": result.sop_steps_remaining,
            "root_cause_found": result.root_cause_found,
            "root_cause_analysis": result.root_cause_analysis,
            "next_steps": result.next_steps,
            "user_recommendations": result.user_recommendations,
            "termination_reason": result.termination_reason,
            "diagnosis_step_count": updated_state["diagnosis_step_count"], # è¿”å›æ›´æ–°åçš„æ­¥éª¤æ•°
            "diagnosis_results": diagnosis_results
        }
    except Exception as e:
        logger.error(f"è¯Šæ–­åæ€å¤±è´¥: {e}")
        # é™çº§å¤„ç† - å¦‚æœåˆ†æå¤±è´¥ï¼Œè¦æ±‚é‡æ–°æŒ‰ç…§SOPæ‰§è¡Œ
        return {
            "is_complete": False,
            "confidence_score": 0.0,
            "sop_steps_completed": [],
            "sop_steps_remaining": ["é‡æ–°æŒ‰ç…§SOPæ‰§è¡Œ"],
            "root_cause_found": False,
            "root_cause_analysis": "åæ€åˆ†æå¼‚å¸¸",
            "next_steps": ["é‡æ–°è·å–SOPå†…å®¹å¹¶ä¸¥æ ¼æ‰§è¡Œ"],
            "user_recommendations": ["è¯·é‡æ–°æäº¤è¯Šæ–­è¯·æ±‚"],
            "termination_reason": "continue",
            "diagnosis_step_count": updated_state["diagnosis_step_count"] # è¿”å›æ›´æ–°åçš„æ­¥éª¤æ•°
        }


def finalize_diagnosis_report(state: DiagnosticOverallState, config: RunnableConfig) -> DiagnosticOverallState:
    """å®Œæˆè¯Šæ–­æŠ¥å‘ŠèŠ‚ç‚¹ - åŸºäºä¸¥æ ¼çš„SOPæ‰§è¡Œç»“æœ"""
    configurable = Configuration.from_runnable_config(config)
    
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    llm = ChatDeepSeek(
        model=configurable.answer_model,
        temperature=0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # è·å–SOPæ‰§è¡ŒçŠ¶æ€
    sop_id = state.get("sop_id", "")
    sop_steps_completed = state.get("sop_steps_completed", [])
    sop_steps_remaining = state.get("sop_steps_remaining", [])
    
    # æ„å»ºSOPæ‰§è¡ŒæŠ¥å‘Š
    current_date = get_current_date()
    
    sop_execution_report = f"""
ã€æ•…éšœè¯Šæ–­æŠ¥å‘Šã€‘
è¯Šæ–­æ—¥æœŸï¼š{current_date}

åŸºæœ¬ä¿¡æ¯ï¼š
- æ•…éšœIPï¼š{state.get('fault_ip', 'æœªæä¾›')}
- æ•…éšœæ—¶é—´ï¼š{state.get('fault_time', 'æœªæä¾›')}
- æ•…éšœç°è±¡ï¼š{state.get('fault_info', 'æœªæä¾›')}
- ä½¿ç”¨SOPï¼š{sop_id}

SOPæ‰§è¡Œæƒ…å†µï¼š
å·²å®Œæˆæ­¥éª¤ï¼š{chr(10).join(sop_steps_completed) if sop_steps_completed else 'æ— '}
å‰©ä½™æ­¥éª¤ï¼š{chr(10).join(sop_steps_remaining) if sop_steps_remaining else 'æ— '}

è¯Šæ–­è¿‡ç¨‹ï¼š
{chr(10).join(state.get('diagnosis_results', ['æœªè¿›è¡Œè¯Šæ–­']))}

è¯·åŸºäºä»¥ä¸ŠSOPæ‰§è¡Œç»“æœï¼Œç”Ÿæˆæœ€ç»ˆçš„è¯Šæ–­æŠ¥å‘Šï¼ŒåŒ…æ‹¬ï¼š
1. SOPæ‰§è¡Œå®Œæ•´æ€§è¯„ä¼°
2. æ•…éšœæ ¹å› åˆ†æï¼ˆå¦‚å·²ç¡®å®šï¼‰
3. è§£å†³æ–¹æ¡ˆå»ºè®®
4. é¢„é˜²æªæ–½å»ºè®®
5. åç»­ç›‘æ§å»ºè®®

æ³¨æ„ï¼šæ‰€æœ‰å»ºè®®å¿…é¡»åŸºäºSOPæ‰§è¡Œç»“æœï¼Œä¸å¾—åç¦»SOPè¦æ±‚ã€‚
"""
    
    # è°ƒç”¨LLMç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
    response = llm.invoke(sop_execution_report)
    
    # æ ¹æ®SOPæ‰§è¡Œå®Œæ•´æ€§ç”Ÿæˆä¸åŒçš„æŠ¥å‘Š
    if len(sop_steps_remaining) == 0:
        # SOPå®Œå…¨æ‰§è¡Œå®Œæ¯•
        final_message = f"""
{response.content}

âœ… SOPæ‰§è¡ŒçŠ¶æ€ï¼šå·²å®Œæˆ
- ä½¿ç”¨SOPï¼š{sop_id}
- å·²å®Œæˆæ­¥éª¤ï¼š{len(sop_steps_completed)}ä¸ª
- å‰©ä½™æ­¥éª¤ï¼š0ä¸ª

âš ï¸ é‡è¦æé†’ï¼š
ä»¥ä¸Šè¯Šæ–­ç»“æœåŸºäºä¸¥æ ¼çš„SOP {sop_id} æ‰§è¡Œã€‚åœ¨æ‰§è¡Œä»»ä½•æ“ä½œå‰ï¼Œè¯·ï¼š
1. ç¡®è®¤å½“å‰ç³»ç»ŸçŠ¶æ€
2. è¯„ä¼°æ“ä½œé£é™©
3. å¤‡ä»½é‡è¦æ•°æ®
4. åœ¨éç”Ÿäº§ç¯å¢ƒæµ‹è¯•

å¦‚éœ€æ‰§è¡Œå»ºè®®çš„è§£å†³æ–¹æ¡ˆï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§SOPè¦æ±‚æ“ä½œã€‚
"""
    else:
        # SOPæœªå®Œå…¨æ‰§è¡Œ
        final_message = f"""
{response.content}

âš ï¸ SOPæ‰§è¡ŒçŠ¶æ€ï¼šæœªå®Œæˆ
- ä½¿ç”¨SOPï¼š{sop_id}
- å·²å®Œæˆæ­¥éª¤ï¼š{len(sop_steps_completed)}ä¸ª
- å‰©ä½™æ­¥éª¤ï¼š{len(sop_steps_remaining)}ä¸ª

ğŸ“‹ æœªå®Œæˆçš„SOPæ­¥éª¤ï¼š
{chr(10).join(sop_steps_remaining)}

é‡è¦è¯´æ˜ï¼š
ç”±äºSOPæœªå®Œå…¨æ‰§è¡Œï¼Œå½“å‰è¯Šæ–­ç»“æœå¯èƒ½ä¸å®Œæ•´ã€‚å»ºè®®ï¼š
1. ç»§ç»­æ‰§è¡Œå‰©ä½™çš„SOPæ­¥éª¤
2. æˆ–è”ç³»æŠ€æœ¯ä¸“å®¶è¿›è¡Œè¿›ä¸€æ­¥è¯Šæ–­
3. é¿å…åœ¨SOPæœªå®Œæˆæ—¶æ‰§è¡Œä¿®å¤æ“ä½œ

è¯·ç¡®ä¿ä¸¥æ ¼æŒ‰ç…§SOPè¦æ±‚å®Œæˆæ‰€æœ‰æ­¥éª¤åå†è¿›è¡Œæ•…éšœä¿®å¤ã€‚
"""
    
    return {
        "messages": [AIMessage(content=final_message)],
        "diagnosis_step_count": state.get("diagnosis_step_count", 0),
        "sop_steps_completed": sop_steps_completed,
        "sop_steps_remaining": sop_steps_remaining
    }


# è¾…åŠ©å‡½æ•°
def sync_sop_state_from_messages(state: DiagnosticOverallState) -> DiagnosticOverallState:
    """åŒæ­¥SOPçŠ¶æ€ - ä»ToolMessageä¸­æå–SOPå†…å®¹"""
    messages = state.get("messages", [])
    # åˆ›å»ºä¸€ä¸ªå¯å˜å‰¯æœ¬ä»¥è¿›è¡Œä¿®æ”¹
    mutable_state = dict(state)

    for msg in reversed(messages):
        # æ£€æŸ¥æ˜¯å¦ä¸ºToolMessageä»¥åŠå·¥å…·åç§°æ˜¯å¦æ­£ç¡®
        if isinstance(msg, ToolMessage) and msg.name == "get_sop_content":
            try:
                result = json.loads(msg.content)
                mutable_state["sop_state"] = result.get("sop_state", "none")
                mutable_state["sop_detail"] = result.get("sop_content")
                # æ‰¾åˆ°åå³å¯é€€å‡ºå¾ªç¯
                break
            except (json.JSONDecodeError, TypeError) as e:
                logger.error(f"è§£æSOPå†…å®¹å¤±è´¥: {e}, å†…å®¹: {msg.content}")
                mutable_state["sop_state"] = "error"
                mutable_state["sop_detail"] = {"error": "Failed to parse SOP content"}
                break
    return mutable_state


# è·¯ç”±å‡½æ•° - å‚è€ƒè°ƒç ”agentçš„æ¡ä»¶è·¯ç”±
def check_info_sufficient(state: QuestionAnalysisState, config: RunnableConfig) -> str:
    """æ£€æŸ¥ä¿¡æ¯æ˜¯å¦å……è¶³"""
    return "plan_tools" if state.get("info_sufficient") else "finalize_answer"


def evaluate_diagnosis_progress(state: DiagnosisReflectionState, config: RunnableConfig) -> str:
    """è¯„ä¼°è¯Šæ–­è¿›åº¦ï¼Œæ ¹æ®SOPæ‰§è¡Œæƒ…å†µå’Œæ ¹å› å‘ç°æƒ…å†µå†³å®šä¸‹ä¸€æ­¥"""
    configurable = Configuration.from_runnable_config(config)
    max_steps = configurable.max_diagnosis_steps
    
    current_steps = state.get("diagnosis_step_count", 0)
    termination_reason = state.get("termination_reason", "continue")
    root_cause_found = state.get("root_cause_found", False)
    
    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•°
    if current_steps >= max_steps:
        logger.warning(f"å·²è¾¾åˆ°æœ€å¤§æ­¥éª¤æ•° {max_steps}ï¼Œå¼ºåˆ¶ç»“æŸè¯Šæ–­")
        return "finalize_answer"
    
    # æ ¹æ®ç»ˆæ­¢åŸå› å†³å®šä¸‹ä¸€æ­¥
    if termination_reason == "root_cause_found" and root_cause_found:
        logger.info("å·²æ‰¾åˆ°æ ¹å› ï¼Œå¯ä»¥æå‰ç»“æŸè¯Šæ–­")
        return "finalize_answer"
    elif termination_reason == "sop_completed":
        logger.info("å·²å®Œæˆæ‰€æœ‰SOPæ­¥éª¤ï¼Œç»“æŸè¯Šæ–­")
        return "finalize_answer"
    elif state.get("is_complete", False):
        # å…¼å®¹å¤„ç†ï¼šå¦‚æœis_completeä¸ºTrueï¼Œä¹Ÿå¯ä»¥ç»“æŸ
        logger.info("è¯Šæ–­å®Œæˆï¼Œç»“æŸè¯Šæ–­")
        return "finalize_answer"
    else:
        # ç»§ç»­æ‰§è¡Œä¸‹ä¸€ä¸ªSOPæ­¥éª¤
        sop_steps_remaining = state.get("sop_steps_remaining", [])
        logger.info(f"ç»§ç»­æ‰§è¡ŒSOPæ­¥éª¤ï¼Œå‰©ä½™æ­¥éª¤: {sop_steps_remaining}")
        return "plan_tools"


# åˆ›å»ºè¯Šæ–­Agentå›¾ - å‚è€ƒè°ƒç ”agentçš„å›¾æ„å»ºæ–¹å¼
builder = StateGraph(DiagnosticOverallState, config_schema=Configuration)

# æ·»åŠ èŠ‚ç‚¹
builder.add_node("analyze_question", analyze_question)
builder.add_node("plan_tools", plan_diagnosis_tools)
builder.add_node("approval", approval_node)

# åˆ›å»ºå·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
ssh_tools = [
    ssh_tool.get_system_info,
    ssh_tool.analyze_processes,
    ssh_tool.check_service_status,
    ssh_tool.analyze_system_logs,
    ssh_tool.execute_system_command
]
sop_tools = [
    sop_tool.get_sop_content,
    sop_tool.get_sop_detail,
    sop_tool.list_sops,
    sop_tool.search_sops
]
all_tools = ssh_tools + sop_tools
tool_node = ToolNode(all_tools)
builder.add_node("execute_tools", tool_node)

builder.add_node("reflection", reflect_diagnosis_progress)
builder.add_node("finalize_answer", finalize_diagnosis_report)

# æ·»åŠ è¾¹ - å‚è€ƒè°ƒç ”agentçš„æ¸…æ™°è¾¹è¿æ¥
builder.add_edge(START, "analyze_question")
builder.add_conditional_edges(
    "analyze_question", 
    check_info_sufficient, 
    ["plan_tools", "finalize_answer"]
)

# æ–°çš„æµç¨‹: plan -> approval -> execute -> reflect
builder.add_edge("plan_tools", "approval")
builder.add_edge("approval", "execute_tools")

# ToolNodeä¼šè‡ªåŠ¨å°†ToolMessageé™„åŠ åˆ°çŠ¶æ€ä¸­
builder.add_edge("execute_tools", "reflection")

builder.add_conditional_edges(
    "reflection", 
    evaluate_diagnosis_progress, 
    ["plan_tools", "finalize_answer"]
)
builder.add_edge("finalize_answer", END)

# ç¼–è¯‘å›¾
graph = builder.compile(name="diagnostic-agent")

# ä¿å­˜å›¾åƒ
try:
graph_image = graph.get_graph().draw_mermaid_png()
with open("diagnostic_agent_graph.png", "wb") as f: 
    f.write(graph_image)
print("å›¾å·²ä¿å­˜åˆ°: diagnostic_agent_graph.png")
except Exception as e:
    logger.error(f"ä¿å­˜å›¾åƒå¤±è´¥: {e}")
