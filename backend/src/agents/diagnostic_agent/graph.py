"""
æ•…éšœè¯Šæ–­ä»£ç† - ä½¿ç”¨LangGraphæ¶æ„ï¼ŒåŸºäºSOPçŸ¥è¯†åº“å’Œæ™ºèƒ½å·¥å…·é€‰æ‹©
é‡æ„ç‰ˆæœ¬ï¼šå‚è€ƒè°ƒç ”agentçš„ç»“æ„ï¼Œä¼˜åŒ–çŠ¶æ€ç®¡ç†å’ŒèŠ‚ç‚¹èŒè´£
"""

import os
import json
import logging
from typing import Dict, Any, List, Optional
from datetime import datetime

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode, tools_condition
from langgraph.types import Send, interrupt

from langchain_core.messages import SystemMessage, AIMessage, HumanMessage, ToolMessage
from langchain_core.runnables import RunnableConfig
from langchain_deepseek import ChatDeepSeek

from agents.diagnostic_agent.state import (
    DiagnosticState,
    QuestionAnalysis,
    DiagnosisProgress,
    SOPDetail,
    SOPStep,
)
from agents.diagnostic_agent.configuration import Configuration
from agents.diagnostic_agent.prompts import (
    get_current_date,
    question_analysis_instructions,
    tool_planning_instructions,
    reflection_instructions,
    final_diagnosis_instructions,
    diagnosis_report_instructions,
)
from agents.diagnostic_agent.tools_and_schemas import QuestionInfoExtraction

# å¯¼å…¥å·¥å…·
from tools import ssh_tool, sop_tool
from dotenv import load_dotenv

load_dotenv()

if os.getenv("DEEPSEEK_API_KEY") is None:
    raise ValueError("DEEPSEEK_API_KEY is not set")

logger = logging.getLogger(__name__)


# èŠ‚ç‚¹å‡½æ•° - å‚è€ƒè°ƒç ”agentçš„æ¸…æ™°ç»“æ„
def analyze_question(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """é—®é¢˜åˆ†æèŠ‚ç‚¹ - ç±»ä¼¼è°ƒç ”agentçš„generate_query"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=1.0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    messages = state.get("messages", [])
    user_question = messages[-1].content if messages else ""
    
    # æ ¼å¼åŒ–æç¤ºè¯
    current_date = get_current_date()
    formatted_prompt = question_analysis_instructions.format(
        current_date=current_date,
        user_question=user_question
    )
    
    # ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºè§£æç”¨æˆ·è¾“å…¥
    result = llm.with_structured_output(QuestionInfoExtraction).invoke(formatted_prompt)
    
    # æ£€æŸ¥å››è¦ç´ æ˜¯å¦éƒ½æœ‰æœ‰æ•ˆå€¼
    info_sufficient = (
        result.fault_ip and result.fault_ip.strip() and result.fault_ip != "å¾…æå–" and
        result.fault_time and result.fault_time.strip() and result.fault_time != "å¾…æå–" and
        result.fault_info and result.fault_info.strip() and result.fault_info != "å¾…æå–" and
        result.sop_id and result.sop_id.strip() and result.sop_id != "å¾…æå–"
    )
    
    # ç”Ÿæˆç¼ºå¤±å­—æ®µåˆ—è¡¨
    missing_fields = []
    if not result.fault_ip or result.fault_ip.strip() == "" or result.fault_ip == "å¾…æå–":
        missing_fields.append("æ•…éšœIP")
    if not result.fault_time or result.fault_time.strip() == "" or result.fault_time == "å¾…æå–":
        missing_fields.append("æ•…éšœæ—¶é—´")
    if not result.fault_info or result.fault_info.strip() == "" or result.fault_info == "å¾…æå–":
        missing_fields.append("æ•…éšœç°è±¡")
    if not result.sop_id or result.sop_id.strip() == "" or result.sop_id == "å¾…æå–":
        missing_fields.append("æ’æŸ¥SOPç¼–å·")
    
    # åˆ›å»ºQuestionAnalysiså¯¹è±¡
    question_analysis = QuestionAnalysis(
        fault_ip=result.fault_ip,
        fault_time=result.fault_time,
        fault_info=result.fault_info,
        sop_id=result.sop_id,
        missing_fields=missing_fields,
        info_sufficient=info_sufficient
    )
    
    return {
        "user_question": user_question,
        "question_analysis": question_analysis
    }


def plan_diagnosis_tools(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """å·¥å…·è§„åˆ’èŠ‚ç‚¹ - ä¸¥æ ¼æŒ‰ç…§SOPæ‰§è¡Œ"""
    configurable = Configuration.from_runnable_config(config)
    llm = ChatDeepSeek(
        model=configurable.query_generator_model,
        temperature=0.1,  # é™ä½æ¸©åº¦ï¼Œç¡®ä¿ä¸¥æ ¼æ‰§è¡Œ
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # ç»‘å®šå·¥å…·åˆ°LLM
    ssh_tools = [
        ssh_tool.get_system_info,
        ssh_tool.analyze_processes,
        ssh_tool.check_service_status,
        ssh_tool.analyze_system_logs,
        ssh_tool.execute_system_command
    ]
    sop_tools = [
        sop_tool.get_sop_content,
        sop_tool.get_sop_detail,
        sop_tool.list_sops,
        sop_tool.search_sops
    ]
    all_tools = ssh_tools + sop_tools
    llm_with_tools = llm.bind_tools(all_tools)
    
    # æ„å»ºå·¥å…·è§„åˆ’æç¤º
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    sop_detail = state.get("sop_detail", SOPDetail())
    sop_state = "loaded" if state.get("sop_loaded", False) else "none"
    
    formatted_prompt = tool_planning_instructions.format(
        fault_ip=question_analysis.fault_ip or "",
        fault_time=question_analysis.fault_time or "",
        fault_info=question_analysis.fault_info or "",
        sop_id=question_analysis.sop_id or "",
        sop_state=sop_state,
        sop_content=sop_detail.description if sop_detail else ""
    )

    # æ„å»ºæ¶ˆæ¯
    messages = state.get("messages", [])
    system_message = SystemMessage(content=formatted_prompt)
    messages_with_system = [system_message] + messages
    
    # è°ƒç”¨LLMç”Ÿæˆå·¥å…·è°ƒç”¨
    response = llm_with_tools.invoke(messages_with_system)
    
    # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†å·¥å…·è°ƒç”¨
    has_tool_calls = hasattr(response, 'tool_calls') and response.tool_calls
    logger.info(f"å·¥å…·è§„åˆ’ç»“æœ: ç”Ÿæˆäº† {len(response.tool_calls) if has_tool_calls else 0} ä¸ªå·¥å…·è°ƒç”¨")
    
    if has_tool_calls:
        for i, tool_call in enumerate(response.tool_calls):
            logger.info(f"å·¥å…·è°ƒç”¨ {i+1}: {tool_call.get('name', 'unknown')}")
    else:
        logger.warning("LLMæ²¡æœ‰ç”Ÿæˆä»»ä½•å·¥å…·è°ƒç”¨ï¼Œè¿™å¯èƒ½å¯¼è‡´è¯Šæ–­æå‰ç»“æŸ")
    
    # è¿”å›æ–°çš„æ¶ˆæ¯ï¼ŒLangGraphä¼šå°†å…¶æ·»åŠ åˆ°çŠ¶æ€ä¸­
    return {"messages": [response]}


def approval_node(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """SOPæ‰§è¡Œç¡®è®¤èŠ‚ç‚¹ - ç¡®è®¤æ¯ä¸ªSOPæ­¥éª¤çš„æ‰§è¡Œ"""
    # è·å–æœ€æ–°çš„å·¥å…·è°ƒç”¨æ¶ˆæ¯
    messages = state.get("messages", [])
    if not messages:
        return {}
    
    last_message = messages[-1]
    
    # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆSOPè¦æ±‚
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        tool_calls = last_message.tool_calls
        question_analysis = state.get("question_analysis", QuestionAnalysis())
        sop_detail = state.get("sop_detail", SOPDetail())
        diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
        
        logger.info(f"å®¡æ‰¹èŠ‚ç‚¹æ£€æŸ¥: SOPå·²åŠ è½½={state.get('sop_loaded', False)}, SOPæ­¥éª¤æ•°={len(sop_detail.steps)}, å½“å‰æ­¥éª¤={diagnosis_progress.current_step}")
        
        # ä»å·¥å…·è°ƒç”¨ä¸­æ‰¾åˆ°åŒ¹é…çš„SOPæ­¥éª¤
        current_step_info = None
        
        # è·å–åŸå§‹SOPæ•°æ®ï¼ˆä»æœ€è¿‘çš„get_sop_contentå·¥å…·æ¶ˆæ¯ä¸­ï¼‰
        raw_sop_data = None
        for msg in reversed(messages):
            if isinstance(msg, ToolMessage) and msg.name == "get_sop_content":
                try:
                    result = json.loads(msg.content)
                    if result.get("success") and result.get("sop_content"):
                        raw_sop_data = result["sop_content"]
                        break
                except (json.JSONDecodeError, TypeError):
                    continue
        
        if not raw_sop_data:
            logger.warning("æ— æ³•è·å–åŸå§‹SOPæ•°æ®ï¼Œè·³è¿‡å®¡æ‰¹æ£€æŸ¥")
            return {}
        
        # æŸ¥æ‰¾åŒ¹é…çš„SOPæ­¥éª¤
        for tool_call in tool_calls:
            tool_name = tool_call.get("name", "")
            tool_args = tool_call.get("args", {})
            
            # è·³è¿‡SOPåŠ è½½ç›¸å…³çš„å·¥å…·è°ƒç”¨
            if tool_name in ["get_sop_content", "get_sop_detail", "list_sops", "search_sops"]:
                logger.info(f"è·³è¿‡SOPå·¥å…·è°ƒç”¨: {tool_name}")
                continue
                
            # åœ¨åŸå§‹SOPæ­¥éª¤ä¸­æŸ¥æ‰¾åŒ¹é…çš„å·¥å…·å’Œå‘½ä»¤
            for sop_step in raw_sop_data.get("steps", []):
                step_tool = sop_step.get("tool", "")
                step_command = sop_step.get("command", "")
                
                # æ£€æŸ¥å·¥å…·åç§°æ˜¯å¦åŒ¹é…
                if tool_name == step_tool:
                    # å¦‚æœæœ‰å‘½ä»¤å‚æ•°ï¼Œæ£€æŸ¥å‘½ä»¤æ˜¯å¦åŒ¹é…
                    if "command" in tool_args:
                        if tool_args["command"] == step_command:
                            current_step_info = SOPStep(
                                title=sop_step.get("action", ""),
                                description=sop_step.get("description", ""),
                                action=sop_step.get("action", ""),
                                requires_approval=sop_step.get("requires_approval", False),
                                status="pending"
                            )
                            logger.info(f"æ‰¾åˆ°åŒ¹é…çš„SOPæ­¥éª¤: {sop_step.get('step', 'N/A')}, åŠ¨ä½œ: {current_step_info.action}, éœ€è¦å®¡æ‰¹: {current_step_info.requires_approval}")
                            break
                    else:
                        # æ²¡æœ‰å…·ä½“å‘½ä»¤å‚æ•°ï¼Œåªæ ¹æ®å·¥å…·åŒ¹é…
                        current_step_info = SOPStep(
                            title=sop_step.get("action", ""),
                            description=sop_step.get("description", ""),
                            action=sop_step.get("action", ""),
                            requires_approval=sop_step.get("requires_approval", False),
                            status="pending"
                        )
                        logger.info(f"æ‰¾åˆ°åŒ¹é…çš„SOPæ­¥éª¤: {sop_step.get('step', 'N/A')}, åŠ¨ä½œ: {current_step_info.action}, éœ€è¦å®¡æ‰¹: {current_step_info.requires_approval}")
                        break
            
            # æ‰¾åˆ°åŒ¹é…çš„æ­¥éª¤å°±é€€å‡º
            if current_step_info:
                break
        
        if not current_step_info:
            logger.info(f"æœªæ‰¾åˆ°åŒ¹é…çš„SOPæ­¥éª¤ï¼Œå·¥å…·è°ƒç”¨: {[tc.get('name') for tc in tool_calls]}")

        # æ£€æŸ¥å½“å‰æ­¥éª¤æ˜¯å¦éœ€è¦å®¡æ‰¹
        if current_step_info and current_step_info.requires_approval:
            logger.info(f"è§¦å‘å®¡æ‰¹æµç¨‹: SOP {question_analysis.sop_id}, æ­¥éª¤: {current_step_info.action}")
            tool_descriptions = []
            for tool_call in tool_calls:
                tool_name = tool_call.get("name", "")
                tool_args = tool_call.get("args", {})
                tool_descriptions.append(f"å·¥å…·: {tool_name}, å‚æ•°: {tool_args}")
            
            # ä¸­æ–­å¹¶è¯·æ±‚ç”¨æˆ·ç¡®è®¤
            interrupt_info = {
                "message": f"æŒ‰ç…§SOP '{question_analysis.sop_id}' è¦æ±‚ï¼Œå³å°†æ‰§è¡Œéœ€è¦å®¡æ‰¹çš„æ­¥éª¤:\n\n"
                           f"**æ­¥éª¤è¯¦æƒ…:** {current_step_info.action}\n"
                           f"**è®¡åˆ’æ“ä½œ:**\n" + "\n".join(tool_descriptions) +
                           f"\n\nç¡®è®¤æ‰§è¡Œï¼Ÿ",
                "tool_calls": tool_calls,
                "sop_id": question_analysis.sop_id,
                "current_sop_step": current_step_info.action,
                "suggestion_type": "sop_execution"
            }
            
            # è°ƒç”¨interruptå¹¶å¤„ç†ç”¨æˆ·ç¡®è®¤ç»“æœ
            user_approved = interrupt(interrupt_info)
            logger.info(f"ç”¨æˆ·å®¡æ‰¹ç»“æœ: {user_approved}")
            
            # æ ¹æ®ç”¨æˆ·ç¡®è®¤ç»“æœè¿”å›ç›¸åº”çŠ¶æ€
            if user_approved:
                # ç”¨æˆ·ç¡®è®¤ï¼Œå…è®¸ç»§ç»­æ‰§è¡Œ
                return {}
            else:
                # ç”¨æˆ·å–æ¶ˆï¼Œä¸­æ­¢æ‰§è¡Œå¹¶è·³è½¬åˆ°æŠ¥å‘Š
                return {
                    "messages": [AIMessage(content="ç”¨æˆ·å–æ¶ˆäº†SOPæ­¥éª¤æ‰§è¡Œï¼Œè¯Šæ–­æµç¨‹å·²ä¸­æ­¢ã€‚")],
                    "diagnosis_progress": DiagnosisProgress(
                        current_step=diagnosis_progress.current_step,
                        max_steps=diagnosis_progress.max_steps,
                        is_complete=True,
                        termination_reason="user_cancelled"
                    )
                }
        
        # å¦‚æœä¸éœ€è¦å®¡æ‰¹ï¼Œåˆ™ä¸è¿”å›ä»»ä½•å†…å®¹ï¼Œç›´æ¥ç»§ç»­
    return {}


def reflect_diagnosis_progress(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """è¯Šæ–­åæ€èŠ‚ç‚¹ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥æ›´æ–°è¯Šæ–­è¿›åº¦"""
    configurable = Configuration.from_runnable_config(config)
    
    # è·å–å½“å‰çŠ¶æ€
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    sop_detail = state.get("sop_detail", SOPDetail())
    messages = state.get("messages", [])
    
    # å¤„ç†SOPåŠ è½½ç»“æœ
    updated_sop_detail = sop_detail
    sop_loaded = state.get("sop_loaded", False)
    
    if messages and isinstance(messages[-1], ToolMessage) and messages[-1].name == "get_sop_content":
        try:
            # è§£æSOPå†…å®¹
            result = json.loads(messages[-1].content)
            if result.get("success") and result.get("sop_content"):
                sop_content = result["sop_content"]
                
                # è§£ææ­¥éª¤å¹¶åˆ›å»ºSOPStepå¯¹è±¡
                steps = []
                for step_data in sop_content.get("steps", []):
                    sop_step = SOPStep(
                        title=step_data.get("title", ""),
                        description=step_data.get("description", ""),
                        action=step_data.get("action", ""),
                        requires_approval=step_data.get("requires_approval", False),
                        status="pending"
                    )
                    steps.append(sop_step)
                
                # åˆ›å»ºSOPDetailå¯¹è±¡
                updated_sop_detail = SOPDetail(
                    sop_id=sop_content.get("id", ""),
                    title=sop_content.get("title", ""),
                    description=sop_content.get("description", ""),
                    steps=steps,
                    total_steps=len(steps)
                )
                sop_loaded = True
                logger.info(f"SOPåŠ è½½æˆåŠŸ: {updated_sop_detail.sop_id}, æ­¥éª¤æ•°: {len(steps)}")
        except (json.JSONDecodeError, TypeError) as e:
            logger.error(f"è§£æSOPå†…å®¹å¤±è´¥: {e}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è¯Šæ–­å·¥å…·æ‰§è¡Œï¼ˆæ’é™¤SOPå·¥å…·ï¼‰
    has_new_diagnostic_execution = False
    if messages and isinstance(messages[-1], ToolMessage):
        last_tool_name = messages[-1].name
        # åªæœ‰éSOPå·¥å…·æ‰ç®—è¯Šæ–­æ­¥éª¤
        if last_tool_name not in ["get_sop_content", "get_sop_detail", "list_sops", "search_sops"]:
            current_step = diagnosis_progress.current_step + 1
            has_new_diagnostic_execution = True
            logger.info(f"æ£€æµ‹åˆ°è¯Šæ–­å·¥å…·æ‰§è¡Œ: {last_tool_name}ï¼Œæ­¥éª¤æ•°æ›´æ–°ä¸º: {current_step}")
        else:
            current_step = diagnosis_progress.current_step
            logger.info(f"æ£€æµ‹åˆ°SOPå·¥å…·æ‰§è¡Œ: {last_tool_name}ï¼Œæ­¥éª¤æ•°ä¿æŒ: {current_step}")
    else:
        # æ²¡æœ‰æ–°çš„å·¥å…·æ‰§è¡Œï¼Œä¿æŒåŸæ­¥éª¤æ•°
        current_step = diagnosis_progress.current_step
        logger.info(f"æ²¡æœ‰æ£€æµ‹åˆ°å·¥å…·æ‰§è¡Œï¼Œæ­¥éª¤æ•°ä¿æŒ: {current_step}")
    
    # ä»æœ€æ–°çš„ToolMessageä¸­æå–è¯Šæ–­ç»“æœ
    diagnosis_results = list(state.get("diagnosis_results", []))
    if has_new_diagnostic_execution:
        last_message = messages[-1]
        diagnosis_results.append(f"Tool: {last_message.name}, Result: {last_message.content}")
    
    # æ£€æŸ¥æ˜¯å¦å®Œæˆè¯Šæ–­ - æ”¾å®½æ¡ä»¶ï¼Œè®©è¯Šæ–­èƒ½å¤Ÿå……åˆ†æ‰§è¡Œ
    is_complete = False
    termination_reason = "continue"
    
    # ä½¿ç”¨é…ç½®çš„max_stepsè¿›è¡Œé€€å‡ºåˆ¤æ–­
    max_steps = diagnosis_progress.max_steps
    
    # è¾¾åˆ°æœ€å¤§æ­¥éª¤é™åˆ¶
    if current_step >= max_steps:
        is_complete = True
        termination_reason = "max_steps_reached"
        logger.warning(f"è¾¾åˆ°æœ€å¤§æ­¥éª¤é™åˆ¶é€€å‡º: {current_step}/{max_steps}")
    # æ£€æŸ¥SOPæ˜¯å¦å·²å®Œå…¨æ‰§è¡Œ
    elif (updated_sop_detail.steps and len(updated_sop_detail.steps) > 0 and 
          current_step >= len(updated_sop_detail.steps) and current_step >= 3):
        is_complete = True
        termination_reason = "sop_completed"
        logger.info(f"SOPæ­¥éª¤å®Œæˆé€€å‡º: {current_step} >= {len(updated_sop_detail.steps)}")
    
    # æ›´æ–°è¯Šæ–­è¿›åº¦
    updated_progress = DiagnosisProgress(
        current_step=current_step,
        max_steps=diagnosis_progress.max_steps,
        is_complete=is_complete,
        confidence_score=min(current_step / max(updated_sop_detail.total_steps, 1), 1.0),
        termination_reason=termination_reason
    )
    
    return {
        "diagnosis_progress": updated_progress,
        "diagnosis_results": diagnosis_results,
        "sop_detail": updated_sop_detail,
        "sop_loaded": sop_loaded
    }


def finalize_diagnosis_report(state: DiagnosticState, config: RunnableConfig) -> Dict[str, Any]:
    """å®Œæˆè¯Šæ–­æŠ¥å‘ŠèŠ‚ç‚¹ - åŸºäºä¸¥æ ¼çš„SOPæ‰§è¡Œç»“æœ"""
    configurable = Configuration.from_runnable_config(config)
    
    # åˆå§‹åŒ–æ¨ç†æ¨¡å‹
    llm = ChatDeepSeek(
        model=configurable.answer_model,
        temperature=0,
        max_retries=2,
        api_key=os.getenv("DEEPSEEK_API_KEY"),
    )
    
    # è·å–çŠ¶æ€ä¿¡æ¯
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    sop_detail = state.get("sop_detail", SOPDetail())
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    diagnosis_results = state.get("diagnosis_results", [])
    
    # ä½¿ç”¨æç¤ºè¯æ¨¡æ¿ç”Ÿæˆæœ€ç»ˆè¯Šæ–­æŠ¥å‘Š
    formatted_prompt = diagnosis_report_instructions.format(
        current_date=get_current_date(),
        fault_ip=question_analysis.fault_ip or 'æœªæä¾›',
        fault_time=question_analysis.fault_time or 'æœªæä¾›',
        fault_info=question_analysis.fault_info or 'æœªæä¾›',
        sop_id=question_analysis.sop_id or 'æœªæŒ‡å®š',
        current_step=diagnosis_progress.current_step,
        total_steps=sop_detail.total_steps,
        completion_status='å·²å®Œæˆ' if diagnosis_progress.is_complete else 'è¿›è¡Œä¸­',
        confidence_score=f"{diagnosis_progress.confidence_score:.2f}",
        diagnosis_results='\n'.join(diagnosis_results) if diagnosis_results else 'æœªè¿›è¡Œè¯Šæ–­'
    )
    
    response = llm.invoke(formatted_prompt)
    
    final_message = f"""
{response.content}

ğŸ“Š è¯Šæ–­æ‰§è¡Œæ‘˜è¦ï¼š
- ä½¿ç”¨SOPï¼š{question_analysis.sop_id}
- æ‰§è¡Œæ­¥éª¤ï¼š{diagnosis_progress.current_step}/{sop_detail.total_steps}
- å®ŒæˆçŠ¶æ€ï¼š{'âœ… å·²å®Œæˆ' if diagnosis_progress.is_complete else 'ğŸ”„ è¿›è¡Œä¸­'}
- ç½®ä¿¡åº¦ï¼š{diagnosis_progress.confidence_score:.1%}

âš ï¸ é‡è¦æé†’ï¼š
ä»¥ä¸Šè¯Šæ–­ç»“æœåŸºäºSOPæ‰§è¡Œã€‚åœ¨æ‰§è¡Œä»»ä½•æ“ä½œå‰ï¼Œè¯·ç¡®è®¤ç³»ç»ŸçŠ¶æ€å¹¶è¯„ä¼°é£é™©ã€‚
"""
    
    return {
        "messages": [AIMessage(content=final_message)],
        "final_diagnosis": response.content
    }


# è·¯ç”±å‡½æ•° - ç®€åŒ–ç‰ˆæœ¬
def check_info_sufficient(state: DiagnosticState, config: RunnableConfig) -> str:
    """æ£€æŸ¥ä¿¡æ¯æ˜¯å¦å……è¶³"""
    question_analysis = state.get("question_analysis", QuestionAnalysis())
    return "plan_tools" if question_analysis.info_sufficient else "finalize_answer"


def evaluate_diagnosis_progress(state: DiagnosticState, config: RunnableConfig) -> str:
    """è¯„ä¼°è¯Šæ–­è¿›åº¦ï¼Œæ ¹æ®æ‰§è¡Œæƒ…å†µå†³å®šä¸‹ä¸€æ­¥"""
    diagnosis_progress = state.get("diagnosis_progress", DiagnosisProgress())
    
    # å¦‚æœè¯Šæ–­å·²æ ‡è®°ä¸ºå®Œæˆï¼Œç›´æ¥ç»“æŸ
    if diagnosis_progress.is_complete:
        logger.info(f"è¯Šæ–­å®Œæˆ: {diagnosis_progress.termination_reason}")
        return "finalize_answer"
    
    # å®‰å…¨æ£€æŸ¥ï¼šé˜²æ­¢æ— é™å¾ªç¯
    if diagnosis_progress.current_step >= diagnosis_progress.max_steps:
        logger.warning(f"è¾¾åˆ°æœ€å¤§æ­¥éª¤é™åˆ¶ï¼Œå¼ºåˆ¶ç»“æŸ: {diagnosis_progress.current_step}/{diagnosis_progress.max_steps}")
        return "finalize_answer"
    
    # ç»§ç»­æ‰§è¡Œä¸‹ä¸€æ­¥
    logger.info(f"ç»§ç»­æ‰§è¡Œï¼Œå½“å‰æ­¥éª¤: {diagnosis_progress.current_step}")
    return "plan_tools"


# ä¿®å¤ï¼šè‡ªå®šä¹‰æ¡ä»¶å‡½æ•°æ¥å†³å®šæ˜¯å¦æœ‰å·¥å…·è°ƒç”¨
def check_tool_calls(state: DiagnosticState, config: RunnableConfig) -> str:
    """æ£€æŸ¥æ˜¯å¦æœ‰å·¥å…·è°ƒç”¨"""
    messages = state.get("messages", [])
    if not messages:
        return "reflection"
    
    last_message = messages[-1]
    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:
        return "approval"
    else:
        return "reflection"
# åˆ›å»ºå·¥å…·æ‰§è¡ŒèŠ‚ç‚¹
ssh_tools = [
    ssh_tool.get_system_info,
    ssh_tool.analyze_processes,
    ssh_tool.check_service_status,
    ssh_tool.analyze_system_logs,
    ssh_tool.execute_system_command
]
sop_tools = [
    sop_tool.get_sop_content,
    sop_tool.get_sop_detail,
    sop_tool.list_sops,
    sop_tool.search_sops
]
all_tools = ssh_tools + sop_tools
tool_node = ToolNode(all_tools)


# åˆ›å»ºè¯Šæ–­Agentå›¾ - ç®€åŒ–ç‰ˆæœ¬
builder = StateGraph(DiagnosticState, config_schema=Configuration)
# æ·»åŠ èŠ‚ç‚¹
builder.add_node("analyze_question", analyze_question)
builder.add_node("plan_tools", plan_diagnosis_tools)
builder.add_node("approval", approval_node)
builder.add_node("execute_tools", tool_node)
builder.add_node("reflection", reflect_diagnosis_progress)
builder.add_node("finalize_answer", finalize_diagnosis_report)
builder.add_edge(START, "analyze_question")
builder.add_conditional_edges("analyze_question", check_info_sufficient, ["plan_tools", "finalize_answer"])
builder.add_conditional_edges("plan_tools",check_tool_calls,{"approval": "approval","reflection": "reflection"})
builder.add_edge("approval", "execute_tools")
builder.add_edge("execute_tools", "reflection")
builder.add_conditional_edges("reflection", evaluate_diagnosis_progress, ["plan_tools", "finalize_answer"])
builder.add_edge("finalize_answer", END)


# ç¼–è¯‘å›¾
graph = builder.compile(name="diagnostic-agent")
# ä¿å­˜å›¾åƒ
graph_image = graph.get_graph().draw_mermaid_png()
with open("diagnostic_agent_graph.png", "wb") as f: 
    f.write(graph_image)
print("å›¾å·²ä¿å­˜åˆ°: diagnostic_agent_graph.png")