import os
from pydantic import BaseModel, Field
from typing import Any, Optional, List, Dict
from langchain_core.runnables import RunnableConfig
from src.apps.agent.service.agent_config_service import AgentConfigService
from src.shared.db.config import get_sync_db
from langchain_openai import ChatOpenAI


class Configuration(BaseModel):
    """é€šç”¨Agenté…ç½®ç±»ï¼Œæ”¯æŒå®Œå…¨å¯é…ç½®åŒ–çš„Agentåˆ›å»º"""

    # === åŸºç¡€Agenté…ç½® ===
    agent_id: str = Field(
        default="generic_agent",
        metadata={"description": "Agentçš„å”¯ä¸€æ ‡è¯†ç¬¦"}
    )
    
    agent_name: str = Field(
        default="é€šç”¨æ™ºèƒ½ä½“",
        metadata={"description": "Agentçš„æ˜¾ç¤ºåç§°"}
    )
    
    agent_description: str = Field(
        default="å¯é…ç½®çš„é€šç”¨æ™ºèƒ½ä½“ï¼Œæ”¯æŒå¤šç§æ¨¡å‹å’Œå·¥å…·",
        metadata={"description": "Agentçš„æè¿°ä¿¡æ¯"}
    )

    # === æ¨¡å‹é…ç½® ===
    model_provider: str = Field(
        default="deepseek",
        metadata={"description": "æ¨¡å‹æä¾›å•†: deepseek, openai, ollama, qwen"}
    )
    
    model_name: str = Field(
        default="deepseek-chat",
        metadata={"description": "ä½¿ç”¨çš„å…·ä½“æ¨¡å‹åç§°"}
    )
    
    model_temperature: float = Field(
        default=0.1,
        metadata={"description": "æ¨¡å‹æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶è¾“å‡ºéšæœºæ€§"}
    )
    
    model_max_tokens: Optional[int] = Field(
        default=4000,
        metadata={"description": "æ¨¡å‹æœ€å¤§è¾“å‡ºtokenæ•°"}
    )
    
    model_max_retries: int = Field(
        default=3,
        metadata={"description": "æ¨¡å‹è°ƒç”¨æœ€å¤§é‡è¯•æ¬¡æ•°"}
    )

    # === å·¥ä½œæµé…ç½® ===
    workflow_type: str = Field(
        default="react",
        metadata={"description": "å·¥ä½œæµç±»å‹: react(æ¨ç†è¡ŒåŠ¨), custom(è‡ªå®šä¹‰å›¾)"}
    )
    
    max_iterations: int = Field(
        default=10,
        metadata={"description": "æœ€å¤§æ‰§è¡Œæ­¥éª¤æ•°"}
    )
    
    enable_memory: bool = Field(
        default=True,
        metadata={"description": "æ˜¯å¦å¯ç”¨å¯¹è¯è®°å¿†"}
    )
    
    enable_streaming: bool = Field(
        default=True,
        metadata={"description": "æ˜¯å¦å¯ç”¨æµå¼è¾“å‡º"}
    )

    # === å·¥å…·é…ç½® ===
    enabled_tool_categories: List[str] = Field(
        default=["search", "calculation", "text_processing"],
        metadata={"description": "å¯ç”¨çš„å·¥å…·ç±»åˆ«åˆ—è¡¨"}
    )
    
    custom_tools: List[str] = Field(
        default=[],
        metadata={"description": "è‡ªå®šä¹‰å·¥å…·åˆ—è¡¨"}
    )
    
    enable_mcp_tools: bool = Field(
        default=True,
        metadata={"description": "æ˜¯å¦å¯ç”¨MCPå·¥å…·é›†æˆ"}
    )
    
    require_approval_tools: List[str] = Field(
        default=[],
        metadata={"description": "éœ€è¦äººå·¥å®¡æ‰¹çš„å·¥å…·åˆ—è¡¨"}
    )

    # === æç¤ºè¯é…ç½® ===
    system_prompt_template: Optional[str] = Field(
        default=None,
        metadata={"description": "è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯æ¨¡æ¿"}
    )
    
    role_description: str = Field(
        default="ä½ æ˜¯ä¸€ä¸ªæœ‰ç”¨çš„AIåŠ©æ‰‹ï¼Œèƒ½å¤Ÿä½¿ç”¨å„ç§å·¥å…·æ¥å¸®åŠ©ç”¨æˆ·è§£å†³é—®é¢˜ã€‚",
        metadata={"description": "Agentçš„è§’è‰²æè¿°"}
    )
    
    personality_traits: List[str] = Field(
        default=["helpful", "professional", "accurate"],
        metadata={"description": "Agentçš„æ€§æ ¼ç‰¹å¾"}
    )

    # === å®‰å…¨é…ç½® ===
    enable_content_filter: bool = Field(
        default=True,
        metadata={"description": "æ˜¯å¦å¯ç”¨å†…å®¹è¿‡æ»¤"}
    )
    
    max_tool_calls_per_turn: int = Field(
        default=5,
        metadata={"description": "æ¯è½®å¯¹è¯æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°"}
    )
    
    timeout_seconds: int = Field(
        default=300,
        metadata={"description": "æ‰§è¡Œè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰"}
    )

    # === å®éªŒæ€§åŠŸèƒ½ ===
    enable_self_reflection: bool = Field(
        default=False,
        metadata={"description": "æ˜¯å¦å¯ç”¨è‡ªæˆ‘åæ€åŠŸèƒ½"}
    )
    
    enable_parallel_execution: bool = Field(
        default=False,
        metadata={"description": "æ˜¯å¦å¯ç”¨å¹¶è¡Œæ‰§è¡Œ"}
    )

    @classmethod
    def from_runnable_config(
        cls, config: Optional[RunnableConfig] = None
    ) -> "Configuration":
        """ä»RunnableConfigåˆ›å»ºé…ç½®å®ä¾‹ï¼Œæ”¯æŒæ•°æ®åº“é…ç½®è¦†ç›–"""
        configurable = (
            config["configurable"] if config and "configurable" in config else {}
        )
        
        # è·å–agent_idï¼Œä¼˜å…ˆä½¿ç”¨configurableä¸­çš„å€¼
        agent_id = configurable.get("agent_id", "generic_agent")
        
        # ä»æ•°æ®åº“åŠ è½½é…ç½®
        db_gen = get_sync_db()
        db = next(db_gen)
        try:
            db_config = AgentConfigService.get_agent_config(agent_id, db)
        finally:
            db.close()
        
        # åˆå¹¶é…ç½®ä¼˜å…ˆçº§: configurable > æ•°æ®åº“ > ç¯å¢ƒå˜é‡ > é»˜è®¤å€¼
        raw_values: Dict[str, Any] = {}
        
        # 1. å…ˆåº”ç”¨é»˜è®¤å€¼ï¼ˆé€šè¿‡Pydanticå­—æ®µå®šä¹‰ï¼‰
        for name, field_info in cls.model_fields.items():
            default_value = field_info.default
            if default_value is not None:
                raw_values[name] = default_value
        
        # 2. åº”ç”¨ç¯å¢ƒå˜é‡
        for name in cls.model_fields.keys():
            env_value = os.environ.get(f"AGENT_{name.upper()}")
            if env_value is not None:
                # ç®€å•ç±»å‹è½¬æ¢
                if name in ["model_temperature"]:
                    raw_values[name] = float(env_value)
                elif name in ["model_max_tokens", "model_max_retries", "max_iterations", "max_tool_calls_per_turn", "timeout_seconds"]:
                    raw_values[name] = int(env_value)
                elif name in ["enable_memory", "enable_streaming", "enable_mcp_tools", "enable_content_filter", "enable_self_reflection", "enable_parallel_execution"]:
                    raw_values[name] = env_value.lower() in ["true", "1", "yes"]
                elif name in ["enabled_tool_categories", "custom_tools", "require_approval_tools", "personality_traits"]:
                    raw_values[name] = env_value.split(",") if env_value else []
                else:
                    raw_values[name] = env_value
        
        # 3. åº”ç”¨æ•°æ®åº“é…ç½®
        if db_config:
            raw_values.update(db_config)
        
        # 4. åº”ç”¨è¿è¡Œæ—¶configurableé…ç½®
        raw_values.update(configurable)
        
        # è¿‡æ»¤Noneå€¼
        values = {k: v for k, v in raw_values.items() if v is not None}
        
        return cls(**values)
    
    def get_api_key(self) -> str:
        """è·å–APIå¯†é’¥ï¼Œå‚è€ƒdiagnostic_agentçš„å®ç°"""
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä¸»è¦ä½¿ç”¨ç¯å¢ƒå˜é‡
        api_key = None
        
        if self.model_provider.lower() == "deepseek":
            api_key = os.environ.get("DEEPSEEK_API_KEY")
        elif self.model_provider.lower() == "openai":
            api_key = os.environ.get("OPENAI_API_KEY")
        else:
            # é»˜è®¤å°è¯•DEEPSEEK_API_KEY
            api_key = os.environ.get("DEEPSEEK_API_KEY")
        
        if not api_key:
            raise ValueError(f"No API key found for provider {self.model_provider}. Please set the appropriate environment variable.")
        
        return api_key

    def create_llm(self, model_name: Optional[str] = None, temperature: Optional[float] = None):
        """åˆ›å»ºLLMå®ä¾‹ï¼Œå‚è€ƒdiagnostic_agentçš„å®ç°"""
        
        # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é…ç½®ä¸­çš„é»˜è®¤å€¼
        actual_model = model_name or self.model_name
        actual_temp = temperature if temperature is not None else self.model_temperature
        
        # è·å–base_url - æ ¹æ®providerè®¾ç½®é»˜è®¤å€¼
        base_url = "https://api.deepseek.com" if self.model_provider.lower() == "deepseek" else "https://api.openai.com/v1"
        
        print(f"ğŸ¤– åˆ›å»ºé€šç”¨Agent LLMå®ä¾‹:")
        print(f"   æä¾›å•†: {self.model_provider}")
        print(f"   æ¨¡å‹: {actual_model}")
        print(f"   æ¸©åº¦: {actual_temp}")
        print(f"   APIç«¯ç‚¹: {base_url}")
        
        return ChatOpenAI(
            model=actual_model,
            temperature=actual_temp,
            max_tokens=self.model_max_tokens,
            max_retries=self.model_max_retries,
            api_key=self.get_api_key(),
            base_url=base_url,
        )

    def to_dict(self) -> Dict[str, Any]:
        """å°†é…ç½®è½¬æ¢ä¸ºå­—å…¸ï¼Œç”¨äºä¿å­˜åˆ°æ•°æ®åº“"""
        return self.model_dump(exclude_none=True)
    
    def get_model_config(self) -> Dict[str, Any]:
        """è·å–æ¨¡å‹ç›¸å…³é…ç½®"""
        return {
            "provider": self.model_provider,
            "model": self.model_name,
            "temperature": self.model_temperature,
            "max_tokens": self.model_max_tokens,
            "max_retries": self.model_max_retries
        }
    
    def get_tool_config(self) -> Dict[str, Any]:
        """è·å–å·¥å…·ç›¸å…³é…ç½®"""
        return {
            "enabled_categories": self.enabled_tool_categories,
            "custom_tools": self.custom_tools,
            "enable_mcp": self.enable_mcp_tools,
            "require_approval": self.require_approval_tools,
            "max_calls_per_turn": self.max_tool_calls_per_turn
        }
    
    def get_workflow_config(self) -> Dict[str, Any]:
        """è·å–å·¥ä½œæµç›¸å…³é…ç½®"""
        return {
            "type": self.workflow_type,
            "max_iterations": self.max_iterations,
            "enable_memory": self.enable_memory,
            "enable_streaming": self.enable_streaming,
            "timeout_seconds": self.timeout_seconds
        }